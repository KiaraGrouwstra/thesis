@online{software20,
  author = {Karpathy, Andrej},
  title = {Software 2.0},
  year = {2017},
  month = {Nov},
  type = {Blog},
  url = {https://medium.com/@karpathy/software-2-0-a64152b37c35},
  urldate = {2019-12-14}
}

@article{church1957applications,
  title={Applications of recursive arithmetic to the problem of circuit synthesis},
  author={Church, Alonzo},
  journal={Institute for Symbolic Logic, Cornell University},
  doi={10.2307/2271310},
  year={1957}
}

@article{gulwani2017program,
  title={Program synthesis},
  author={Gulwani, Sumit and
          Polozov, Oleksandr and
          Singh, Rishabh and
          others},
  journal={Foundations and Trends in Programming Languages},
  volume={4},
  number={1-2},
  pages={1--119},
  year={2017},
  doi={10.1561/2500000010},
  url={https://www.nowpublishers.com/article/Details/PGL-010}
}
% approaches: deductive (theorem provers, full specification) vs. grammar-based e.g. based on examples
% challenges: program space (full enumeration won't terminate), user intent (full specification unrealistic)
% dimensions: kind of constraints (user intent), search space of programs, search technique
% - user intent: logical specification (tricky to write), examples (potentially by property or iteratively), traces (step-by-step behavior on given input, e.g. intermediate states UI), natural language, partial programs, related programs (optimization, deobfuscation, inverses)
% - search space: expressiveness vs efficiency, imperative/functional, DSLs, control structure (e.g. partial program with holes)
% - search technique:
%   - enumerative search: enumerate/order/check, unscalable, breadth-first, bottom-up i.e. small first
%   - deduction: divide-and-conquer top-down search, depth-first, recursively reduce to sub-problems, propagating constraints
%   - constraint solving:
%     - constraint generation:
%       - invariant-based: full proof
%       - input-based: proof it works for certain inputs, typically paired with counter-example guided inductive synthesis (CEGIS) strategy
%       - path-based: in-between, works for inputs following some paths
%     - constraint resolution: SAT/SMT
%   - statistical: ML of probabilistic grammars, genetic programming, MCMC sampling, probabilistic inference
%   - combination: augment enumerative search or deduction by providing choices' likelihood
% general principles:
% - Second-Order Problem Reduction: reduce to first-order search problem using templates so we can use SMT/SAT solvers. sketches have holes fixed to e.g. integer, templates have holes for arbitrary expressions.
% - Oracle-Guided Synthesis: picking templates non-trivial, instead verify validity of candidate solutions.
%   - counterexample-guided inductive synthesis (CEGIS): either the candidate turns out valid, or we find a counter-example.
%   - oracle-guided inductive synthesis (OGIS) first uses simplified spec.
%   - Distinguishing Inputs: use loopless programs, check program distinguishability on concrete inputs.
%   - End-user confidence: e.g. find distinguishing input, ask user which program handles it correctly (if any).
%   - Syntactic Bias: restrict programs
%     - Sketching: int holes
%     - Syntax-Guided Synthesis (SyGuS): logical spec + syntactic template to constrain space. find candidates in grammar G satisfying spec φ in theory (language) T. competition SyGuS-Comp.
%     - DSL Design: factors:
%       - Balanced Expressivity
%       - Choice of Operators
%       - Naturalness
%       - Efficiency
%     - Optimization:
%       - Metrics: Program speed, Robustness, Naturalness/legibility
%       - Ranking:
%         - MCMC (smart hill climber)
%         - version space algebra (VSA)s: rankable repesentation of program space
%         - ml
%         - metasketches: ordered family of partial programs w/ cost function + gradient
% - Enumerative Search
%   - Enumerative Search
%     - Top-down Tree Search: like what I do for program generation
%     - Bottom-up Tree Search: dedupe bottom-up to prune search space (e.g. x+y vs y+x)
%   - Bidirectional Enumerative Search: forward search from inputs + backward from outputs.
%   - Offline Exhaustive Enumeration and Composition: hash programs by i/o.
% - Constraint Solving: encoding spec + syntactic restrictions in one formula.
%   - Component-based synthesis: use each component once.
%     - End-to-end SMT Encoding: ensure program:
%       - well-formed: syntax, deduped, acyclical
%       - component usage: respect types?
%       - specification: i/o correct
%     - Sketch generation and completion: less restrictive
%   - Solver-Aided Programming: extend language with SAT/SMT-powered constructs
%   - Inductive Logic Programming: synthesizing first-order rules/relations, not functional expressions.
% - Stochastic Search: learn a distribution over the space of programs in the hypothesis space conditioned on the specification, then sample
%   - Metropolis-Hastings Algorithm for Sampling Expressions: probability based on meeting specification
%   - Genetic Programming: natural selection/variation
%   - Machine Learning: learn a probability distribution over the space of programs conditioned by the specification
%   - Neural Program Synthesis: induction vs synthesis (e.g. NSPS)
% - Programming by Example (PBE)
%   - Problem Definition: use inputs + output examples/constraints. characterized by ease of use and ambiguity. find just the few good programs that match intent and generalize.
%   - Version Space Algebra: constraining DSL by picking only a few examples for each grammar production.
%   - Deduction-Based Techniques: push examples thru grammar top-down. aka divide-and-conquer search, top-down search, and backpropagation-based search. done by (a) inverse operator semantics, or (b) type-theoretic.
%     - Inverse Semantics: mitigating non-trivial inverse:
%       - witness function: pick only likely (reverse) inputs
%       - constraints: property of output
%       - Case split: Per-parameter decomposition of inverse semantics.
%     - Type-Based Perspective: propagate type refinements.
%   - Ambiguity Resolution: getting user intent harder with few samples in a rich DSL.
%     - Ranking: learning-to-rank any correct program on top.
%     - Active Learning: ask feedback by distinguishing inputs.
% - Future Work: Debuggability, Multi-modal input, Adaptivity, Statistical techniques, Scaling, Knowledge transfer, Industrialization
% [79] SmartSynth: synthesizing smartphone automation scripts from natural language

@article{nps,
  author    = {Neel Kant},
  title     = {Recent Advances in Neural Program Synthesis},
  journal   = {CoRR},
  volume    = {abs/1802.02353},
  year      = {2018},
  url       = {http://arxiv.org/abs/1802.02353},
  archivePrefix = {arXiv},
  eprint    = {1802.02353}
}
% Though there are still some firm purists in both, the symbolic and connectionist AI camps, the consensus is that neither approach is likely to solve program synthesis in isolation. What is important is that the two paradigms have \textbf{complementary} strengths and weaknesses in their abilities to \emph{represent} and \emph{learn} knowledge. Thus, it is natural to believe that a \textbf{hybrid system} is the most promising path forward.

% 5.2 Future Research Recommendations
% 6. Building more complete solutions will no doubt require greater \textbf{automation in learning}. Current methods rely heavily on hand-crafted curricula to incrementally challenge a model and improve generalization.

% My main take-away from this paper now is that most other neural techniques, on the basis of their sequence-to-sequence approach, lack an inherent incremental state and as such have to do a bunch of learning tasks just to get a sense of how to construct and update a (memorized) state so as to ultimately obtain a correct program.
% The way I see it NSPS just completely side-steps all these extra learning tasks, significantly simplifying the learning problem.

% aka Neural FlashFill
@article{nsps,
  author    = {Emilio Parisotto and
               Abdel{-}rahman Mohamed and
               Rishabh Singh and
               Lihong Li and
               Dengyong Zhou and
               Pushmeet Kohli},
  title     = {Neuro-Symbolic Program Synthesis},
  journal   = {CoRR},
  volume    = {abs/1611.01855},
  year      = {2016},
  url       = {http://arxiv.org/abs/1611.01855},
  archivePrefix = {arXiv},
  eprint    = {1611.01855}
}
% no code; (1) cross correlation I/O network embeds in/out examples, (2) Recursive-Reverse-Recursive Neural Network (R3NN) incrementally synthesizes AST. R3NN has node representations, then calculates representations bottom-up then top-down to get representations for the next hole to fill. tests on flashfill. ops Concat/ConstStr/SubStr/Position/Direction/Regex.

@article{alphanpi,
  author    = {Thomas Pierrot and
               Guillaume Ligner and
               Scott E. Reed and
               Olivier Sigaud and
               Nicolas Perrin and
               Alexandre Laterre and
               David Kas and
               Karim Beguir and
               Nando de Freitas},
  title     = {Learning Compositional Neural Programs with Recursive Tree Search and Planning},
  journal   = {CoRR},
  volume    = {abs/1905.12941},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.12941},
  archivePrefix = {arXiv},
  eprint    = {1905.12941}
}
% [blog](https://www.instadeep.com/research-article/towards-compositionality-in-deep-reinforcement-learning/)
% Neural Programmer-Interpreter (NPI) + AlphaZero = AlphaNPI. tests on sorting/hanoi tasks. ops as NPI.

% NMT
@inproceedings{kalchbrenner2013recurrent,
  title={Recurrent continuous translation models},
  author={Kalchbrenner, Nal and
          Blunsom, Phil},
  editor={},
  booktitle={Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing},
  pages={1700--1709},
  url={https://www.aclweb.org/anthology/D13-1176.pdf},
  year={2013}
}

@article{npi,
  title={Neural programmer-interpreters},
  author={Reed, Scott and
          De Freitas, Nando},
  url={https://arxiv.org/abs/1511.06279},
  journal={arXiv preprint arXiv:1511.06279},
  year={2015}
}
% DeepMind, seq2seq. tests on add/sort / canonicalizing 3d models. ops reset/bubble/rshift/lshift/compswap/ptr1l/ptr1r/ptr2l/ptr2r/swap/stop.

% holes
@inproceedings{hashimoto1997typed,
  title={A typed context calculus},
  author={Hashimoto, Masatomo and
          Ohori, Atsushi},
  editor={},
  booktitle={Theoretical Computer Science},
  year={1997},
  url={https://www.sciencedirect.com/science/article/pii/S0304397500001742},
  doi={10.1016/S0304-3975(00)00174-2},
  organization={Citeseer}
}

inproceedings{deepproblog,
  title={Deepproblog: Neural probabilistic logic programming},
  author={Manhaeve, Robin and
          Dumancic, Sebastijan and
          Kimmig, Angelika and
          Demeester, Thomas and
          De Raedt, Luc},
  editor={},
  booktitle={Advances in Neural Information Processing Systems},
  url={https://arxiv.org/abs/1805.10872},
  pages={3749--3759},
  year={2018}
}
% differentiable [ProbLog](https://dtai.cs.kuleuven.be/problog/).
% Emile: less relevant cuz untyped? tests on add/sort/algebra on pics/list/text. induction, no ops.

inproceedings{problog,
  title={ProbLog: A Probabilistic Prolog and Its Application in Link Discovery},
  author={De Raedt, Luc and
          Kimmig, Angelika and
          Toivonen, Hannu},
  editor={},
  url={https://dtai.cs.kuleuven.be/problog/},
  booktitle={IJCAI},
  volume={7},
  pages={2462--2467},
  year={2007},
  organization={Hyderabad}
}

@article{dilp,
  title={Learning explanatory rules from noisy data},
  author={Evans, Richard and
          Grefenstette, Edward},
  url={https://arxiv.org/abs/1711.04574},
  journal={Journal of Artificial Intelligence Research},
  volume={61},
  pages={1--64},
  year={2018}
}
% DeepMind, [code](https://github.com/ai-systems/DILP-Core)
% Differentiable Inductive Logic Programming (∂ILP) = ILP (data efficient) + NNs' ability to handle ambiguity. trained on various symbolic tasks. uses given template so just handles induction. check if this can do types?
% see pic on p.31. tests on [20 symbolic tasks](https://arxiv.org/pdf/1711.04574.pdf#page=27) (see appendix G: arithmetic, lists, family tree, graphs). task-dependent ops. not sure I can add value here if the template is set.

% #neural-guided-deductive-search
@article{deepcoder,
  title={Deepcoder: Learning to write programs},
  author={Balog, Matej and
          Gaunt, Alexander L and
          Brockschmidt, Marc and
          Nowozin, Sebastian and
          Tarlow, Daniel},
  url={https://www.microsoft.com/en-us/research/publication/deepcoder-learning-write-programs/},
  journal={arXiv preprint arXiv:1611.01989},
  year={2016}
}
% (repos [1](https://github.com/HiroakiMikami/deep-coder), [2](https://github.com/dkamm/deepcoder), [3](https://github.com/amitz25/PCCoder))
% train a neural network to predict properties of the program that generated the outputs from the inputs to augment search techniques, e.g. enumerative search, SMT-based solver, depth-first search (DFS), 'sort and add' enumeration, sketch, λ^2. tested on functional programs. does not use a node tree though, so not amenable to my type-based approach.

% #neural-guided-deductive-search
@article{kalyan2018neural,
  title={Neural-guided deductive search for real-time program synthesis from examples},
  author={Kalyan, Ashwin and
          Mohta, Abhishek and
          Polozov, Oleksandr and
          Batra, Dhruv and
          Jain, Prateek and
          Gulwani, Sumit},
  url={https://www.microsoft.com/en-us/research/publication/neural-guided-deductive-search-real-time-program-synthesis-examples/},
  journal={arXiv preprint arXiv:1804.01186},
  year={2018}
}
% https://www.microsoft.com/en-us/research/blog/neural-guided-deductive-search-best-worlds-approach-program-synthesis/
% - combines symbolic logic + statistical models by 'branch & bound' from combinatorial optimization.
% - deductive search: decompose synthesis into sub-problems, Markovian so can do supervised learning.
% - NGDS: find which sub-problems are useful, predict program generalization by LSTM scoring DSL production rules on i/o.
% - evaluated on string transformation (PROSE) against RobustFill / DeepCoder.
% - deductive search seems kinda like pruning by type reasoning, though here it's learned. I guess the stronger the types tho, the less needs learning.
% - train separate models for different DSL levels, symbols, or even productions.
% - I *think* this seems iterative top-down, so seems applicable for me, tho no code.
% - this made me realize you may want to factor in existing operations on i/o to simplify the problem for the given sub-node.
% - sub-problems mentioned sounds relevant, and their previous paper FlashMeta (which this builds on) is mentioned in a [repo](https://github.com/reudismam/Refazer/blob/58f68f2c3f93e148a50f2eb09879a7bbe7fd6e3a/ProgramSynthesis/ProseFunctions/RelativePositioning/RightWitnessFunction.cs), though I'm not sure where this is imported from.
% - the used framework PROSE [offers holes](https://microsoft.github.io/prose/documentation/prose/usage/), implying they support the top-down incremental approach I'm hoping these papers are using.
% - unlike deepcoder's bottom-up, this seems top-down, prioritizing productions (then higher-level constructs) to direct a search. can probably combine this with NSPS!
% - PROSE's witness functions for constraint propagation look super interesting! I kinda want this both for types and for input/output examples...

@inproceedings{flashmeta,
  title={FlashMeta: a framework for inductive program synthesis},
  author={Polozov, Oleksandr and
          Gulwani, Sumit},
  editor={},
  url={https://dl.acm.org/citation.cfm?id=2814310},
  booktitle={ACM SIGPLAN Notices},
  volume={50},
  number={10},
  pages={107--126},
  year={2015},
  doi={10.1145/2814270.2814310},
  organization={ACM}
}

article{rnngrammars,
  title={Recurrent neural network grammars},
  author={Dyer, Chris and
          Kuncoro, Adhiguna and
          Ballesteros, Miguel and
          Smith, Noah A},
  url={https://arxiv.org/abs/1602.07776},
  journal={arXiv preprint arXiv:1602.07776},
  year={2016}
}
% probabilistic model of phrase-structure trees that can be trained generatively and used as a language model or a parser. seems aimed at language models, i.e. mimicking existing usage, which for program synthesis might be secondary to finding programs properly mapping input to output.

@article{bunel2018leveraging,
  title={Leveraging grammar and reinforcement learning for neural program synthesis},
  author={Bunel, Rudy and
          Hausknecht, Matthew and
          Devlin, Jacob and
          Singh, Rishabh and
          Kohli, Pushmeet},
  url={https://arxiv.org/abs/1805.04276},
  journal={arXiv preprint arXiv:1805.04276},
  year={2018}
}
% supervised + RL to generate semantically correct programs. train to generate syntactically correct programs that fulfill the specification. only applies for sequence approach, which doesn't match the trees I want...

@inproceedings{typedmil,
  title={Typed meta-interpretive learning of logic programs},
  author={Morel, Rolf and
          Cropper, Andrew and
          Ong, C-H Luke},
  editor={},
  url={https://www.researchgate.net/profile/Andrew_Cropper/publication/331100541_Typed_meta-interpretive_learning_of_logic_programs/links/5c65c7bd299bf1d14cc75a39/Typed-meta-interpretive-learning-of-logic-programs.pdf},
  booktitle={European Conference on Logics in Artificial Intelligence},
  pages={198--213},
  year={2019},
  doi={10.1007/978-3-030-19570-0_13},
  organization={Springer}
}
% Prolog/Python [code](https://github.com/rolfmorel/jelia19-typedmil)
% typed MIL (~= inductive logic programming (ILP)) reduces space by a cubic factor. tests on [list manipulation](https://github.com/rolfmorel/jelia19-typedmil/tree/master/experiments/03-evaluation). [ops](https://github.com/rolfmorel/jelia19-typedmil/blob/master/experiments/03-evaluation/nestedincr/gen_test_prolog.py#L43-L67). types: list<T>, int, char.

@article{wang2018predicting,
  title={Predicting Haskell Type Signatures From Names},
  author={Wang, Bowen},
  journal = {Semantic Scholar},
  journaltitle = {Semantic Scholar},
  url={https://people.cs.uchicago.edu/~rchugh/static/theses/bowen-wang-thesis.pdf},
  year={2018}
}
% encode name/context, recursively select (non-)arrow

@inproceedings{lambda2,
  title={Synthesizing data structure transformations from input-output examples},
  author={Feser, John K and
          Chaudhuri, Swarat and
          Dillig, Isil},
  editor={},
  url={https://www.cs.utexas.edu/~isil/pldi15b.pdf},
  booktitle={ACM SIGPLAN Notices},
  volume={50},
  number={6},
  pages={229--239},
  year={2015},
  doi={10.1145/2813885.2737977},
  organization={ACM}
}
% 2015, 145 cites, [code](https://github.com/jfeser/L2), λ^2
% OCaml+Python PBE from 7 combinators by inductive generalisation + (limited) deduction + enumerative search. typed, incremental, holes. old functional synthesis paper that got good improvement from types. tests on 40 data structure manipulation tasks (lists, trees, nested). ops: map, maptree, filter, foldl, foldr, foldtree, recl. 41 ops (lists, trees, nested).

@article{myth,
  title={Type-and-example-directed program synthesis},
  author={Osera, Peter-Michael and
          Zdancewic, Steve},
  url={https://dl.acm.org/citation.cfm?id=2738007},
  journal={ACM SIGPLAN Notices},
  volume={50},
  number={6},
  pages={619--630},
  doi={10.1145/2813885.2738007},
  year={2015}
}
% 100 cites, [code](https://github.com/psosera/thesis/blob/master/code/LambdaTermsCounts.hs)
% Haskell/OCaml PBE by types + i/o. shows own synthesis/typecheck rules, library. tests on 40 (figure #9) + 5 (#10) functions ([details](https://github.com/psosera/thesis/blob/master/content/benchmark-suite.tex)). code repo unreleased.
% list/tree categories polymorphic, bool/nat aren't. eval during enum, standardize on beta-normal, typechecks partial functions, lists relevant math. top-down generates refinement trees by cycling through steps adding a type (type refinement) or potential values (guessing enumeratively) by examples. essentially constructs a simple idea that works for one example, check which other examples fail, and which parts of the program should be refined to fix those. pattern matches ADTs like lists (nil). enforces recursion. ppt claims ml-syn incomplete? lists several directions for future work. seems like a good paper, I should look for citing papers in case any has open-sourced a similar solution. should recheck if this does 'holes' though, as it seemed to generate complete programs?

@inproceedings{scout,
  title={Programming assistance for type-directed programming},
  author={Osera, Peter-Michael},
  editor={},
  url={https://www.cs.grinnell.edu/~osera/publications/osera-tyde-2016.pdf},
  booktitle={Proceedings of the 1st International Workshop on Type-Driven Development},
  pages={56--57},
  year={2016},
  doi={10.1145/2976022.2976027},
  organization={ACM}
}
% no code?, bridge auto-completion / program synthesis with interactive programming assistant for type-directed programming.

@inproceedings{synquid,
  title={Program synthesis from polymorphic refinement types},
  author={Polikarpova, Nadia and
          Kuraj, Ivan and
          Solar-Lezama, Armando},
  editor={},
  url={https://dl.acm.org/citation.cfm?id=2908093},
  booktitle={ACM SIGPLAN Notices},
  volume={51},
  number={6},
  pages={522--538},
  year={2016},
  doi={10.1145/2980983.2908093},
  organization={ACM}
}
% [code](https://bitbucket.org/nadiapolikarpova/synquid)
% code from refinement types. synthesize Haskell-like Synquid by SMT-solver from modular refinement type reconstruction to allow type-checking partial programs using liquid types.

@mastersthesis{tamandu,
  title={Top-Down Inductive Synthesis with Higher-Order Functions},
  author={Maximova, Alexandra},
  url={https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/155821/eth-49631-01.pdf},
  year={2016},
  school={ETH Z{\"u}rich}
}
% [code](https://github.com/shasfin/ml4fp2016)
% PBE in toy language from OCaml w/ large library (37 components), based on best-first enumeration combined with type-based pruning, evaluated on 23 functions (table 4.2).

online{tamandurepo,
  author={Maximova, Alexandra},
  title = {ml4fp2016},
  year = {2016},
  month = {Jan},
  url = {https://github.com/shasfin/ml4fp2016},
  urldate = {2020-05-27}
}

@article{hornclauses,
  title={Functional Program Synthesis from Relational Specifications},
  author={Nakao, Shuu and
          Satake, Yuki and
          Amano, Hiroshi},
  url={http://jssst.or.jp/files/user/taikai/2017/PPL/ppl3-1.pdf},
  journal={Japan Computer Science Conference Journal},
  volume={34},
  pages={207--220},
  year={2017}
}
  title={関係的仕様からの関数型プログラム合成},
  author={中尾收 and
          佐竹佑規 and
          海野広志},
  journal={日本ソフトウェア科学会大会論文集},
% Haskell synthesis using Horn clauses.

@phdthesis{gissurarson2018suggesting,
  title={Suggesting Valid Hole Fits for Typed-Holes in Haskell},
  author={Gissurarson, Matth{\'\i}as P{\'a}ll},
  url={https://www.mpg.is/papers/gissurarson2018suggesting-msc.pdf},
  year={2018},
  school={Master’s thesis. Chalmers University of Technology, University of Gothenburg~…}
}
% [code](https://github.com/Tritlo/ExampleHolePlugin)
% integrates hole filler into GHC. mentions synthesizers insynth (JVM), [djinn](https://github.com/augustss/djinn/) (haskell, non-polymorphic). dependently typed languages: type inference undecidable. mentions hole-filling for agda and idris. great explanation of program synthesis on typed holes at 3.1.

@online{djinn,
  author = {Lennart Augustsson},
  title = {djinn: Generate Haskell code from a type},
  year = {2014},
  month = {Sep},
  url = {http://hackage.haskell.org/package/djinn},
  urldate = {2020-01-24}
}

@article{guospeeding,
  title={Speeding up Type-Driven Program Synthesis with Polymorphic Succinct Types},
  journaltitle = {ICFP},
  url={https://icfp18.sigplan.org/getImage/orig/icfp18src-zheng-guo.pdf},
  year={2018},
  author={Guo, Zheng}
}
% [code](https://github.com/aaronguo1996/Synquid)
% generalize succinct types for polymorphism. to find which types are used under polymorphism, abstract the types into coarse-grained succinct types, unordered param type sets describing function i/o.

@inproceedings{eguchi2018automated,
  title={Automated Synthesis of Functional Programs with Auxiliary Functions},
  author={Eguchi, Shingo and
          Kobayashi, Naoki and
          Tsukada, Takeshi},
  editor={},
  url={https://www-kb.is.s.u-tokyo.ac.jp/~koba/papers/aplas18-long.pdf},
  booktitle={Asian Symposium on Programming Languages and Systems},
  pages={223--241},
  year={2018},
  doi={10.1007/978-3-030-02768-1_13},
  organization={Springer}
}
% extension of Synquid to enable top-down iterative synthesis of programs with auxiliary functions using holes.

@inproceedings{scythe,
  title={Constraint-based type-directed program synthesis},
  author={Osera, Peter-Michael},
  editor={},
  url={https://arxiv.org/abs/1907.03105},
  booktitle={Proceedings of the 4th ACM SIGPLAN International Workshop on Type-Driven Development},
  pages={64--76},
  year={2019},
  organization={ACM}
}
% no code?, synthesis from type. “infer while enumerate” approach to polymorphic type instantiation. uses WIP Haskell synthesis tool Scythe. no task!

@inproceedings{temporalstreamlogic,
  title={Temporal stream logic: Synthesis beyond the bools},
  author={Finkbeiner, Bernd and
          Klein, Felix and
          Piskac, Ruzica and
          Santolucito, Mark},
  editor={},
  url={https://arxiv.org/abs/1712.00246},
  booktitle={International Conference on Computer Aided Verification},
  pages={609--629},
  year={2019},
  organization={Springer}
}
% CEGAR-based synthesis (from formal spec) separating control and data. benchmarks: synthesized music player Android app, controller for autonomous vehicle in the Open Race Car Simulator (TORCS).

article{combopt,
  title={Machine Learning for Combinatorial Optimization: a Methodological Tour d'Horizon},
  author={Bengio, Yoshua and
          Lodi, Andrea and
          Prouvost, Antoine},
  url={https://arxiv.org/abs/1811.06128},
  journal={arXiv preprint arXiv:1811.06128},
  year={2018}
}
% - is it useful to frame program synthesis as a [Combinatorial Optimization](https://paperswithcode.com/task/combinatorial-optimization) problem (not unlike the TSP)?
% - how do they differ? -- CO implies a loss/reward per configuration. for ML I should need a loss anyway tho, so this seems reasonable. the sub-field of linear programming requires linear relationships, which I doubt apply here.
% - what are the differences between their algorithms?

@inproceedings{houdini,
  title={Houdini: Lifelong learning as program synthesis},
  author={Valkov, Lazar and
          Chaudhari, Dipak and
          Srivastava, Akash and
          Sutton, Charles and
          Chaudhuri, Swarat},
  editor={},
  url={https://arxiv.org/abs/1804.00218},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8687--8698},
  year={2018}
}
% [code](https://github.com/capergroup/houdini)
% NNs as typed differentiable functional programs to compose a library of neural functions to mix perception and procedural reasoning. library: NN, compose, map, fold, conv, on list/graph/tensor of bool/real. synth: generate (heuristically-guided top-down iterative refinement) + learn, evaluated on lifelong learning. suggests incorporating search strategies from NAS. not actually doing program synthesis tho... tests on several lifelong learning tasks (mix perceptual/algorithmic knowledge): recognize_digit, classify_digit, is_toy, regress_speed, regress_mnist, count_digit, count_toy, sum_digits, shortest_path_street, shortest_path_mnist. ops: hole, map, fold, convolution, compose.

@article{feser2016differentiable,
  author    = {John K. Feser and
               Marc Brockschmidt and
               Alexander L. Gaunt and
               Daniel Tarlow},
  title     = {Neural Functional Programming},
  journal   = {CoRR},
  volume    = {abs/1611.01988},
  year      = {2016},
  url       = {http://arxiv.org/abs/1611.01988},
  archivePrefix = {arXiv},
  eprint    = {1611.01988},
  timestamp = {Mon, 13 Aug 2018 16:47:13 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/FeserBGT16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{rocktaschel2017end,
  title={End-to-end differentiable proving},
  author={Rockt{\"a}schel, Tim and Riedel, Sebastian},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3788--3800},
  url={http://papers.nips.cc/paper/6969-end-to-end-differentiable-proving},
  year={2017}
}

@article{idris,
  title={Idris, a general-purpose dependently typed programming language: Design and implementation},
  author={Brady, Edwin},
  url={https://eb.host.cs.st-andrews.ac.uk/drafts/impldtp.pdf},
  journal={Journal of functional programming},
  volume={23},
  number={5},
  pages={552--593},
  doi={10.1017/S095679681300018X},
  year={2013}
}
% [code](https://github.com/idris-lang/Idris-dev)
% covers language design including holes (section 4).

@book{brady2017type,
  title={Type-driven development with Idris},
  author={Brady, Edwin},
  year={2017},
  publisher={Manning Publications Company}
}

@article{forth,
  author    = {Sebastian Riedel and
                Matko Bosnjak and
                Tim Rockt{\"{a}}schel},
  title     = {Programming with a Differentiable Forth Interpreter},
  journal   = {CoRR},
  volume    = {abs/1605.06640},
  year      = {2016},
  url       = {http://arxiv.org/abs/1605.06640},
  archivePrefix = {arXiv},
  eprint    = {1605.06640}
}

% 78 cites
@article{terpret,
  title={Terpret: A probabilistic programming language for program induction},
  author={Gaunt, Alexander L and
          Brockschmidt, Marc and
          Singh, Rishabh and
          Kushman, Nate and
          Kohli, Pushmeet and
          Taylor, Jonathan and
          Tarlow, Daniel},
  journal={arXiv preprint arXiv:1608.04428},
  url={https://arxiv.org/abs/1608.04428},
  year={2016}
}

@inproceedings{rosette,
  title={Growing solver-aided languages with rosette},
  author={Torlak, Emina and Bodik, Rastislav},
  editor={},
  booktitle={Proceedings of the 2013 ACM international symposium on New ideas, new paradigms, and reflections on programming \& software},
  pages={135--152},
  year={2013},
  url={https://homes.cs.washington.edu/~emina/pubs/rosette.onward13.pdf},
  doi={10.1145/2509578.2509586},
  organization={ACM}
}

@article{lambdacalculus,
  title={A set of postulates for the foundation of logic},
  author={Church, Alonzo},
  journal={Annals of mathematics},
  pages={346--366},
  doi={10.2307/1968337},
  year={1932}
}

@article{currying,
  title={{\"U}ber die Bausteine der mathematischen Logik},
  author={Sch{\"o}nfinkel, Moses},
  journal={Mathematische annalen},
  volume={92},
  number={3},
  pages={305--316},
  year={1924}
}

@techreport{fortran95,
  type = {Standard},
  key = {ISO/IEC 1539-1:1997},
  url = {https://www.iso.org/standard/26933.html},
  author = {ISO},
  year = {1997},
  month = {Dec},
  title = {Information technology --- Programming languages --- Fortran - Part 1: Base language},
  address = {Geneva, CH},
  institution = {International Organization for Standardization}
}

@article{abstractsyntaxnetworks,
  author    = {Maxim Rabinovich and
               Mitchell Stern and
               Dan Klein},
  title     = {Abstract Syntax Networks for Code Generation and Semantic Parsing},
  journal   = {CoRR},
  volume    = {abs/1704.07535},
  year      = {2017},
  url       = {http://arxiv.org/abs/1704.07535},
  archivePrefix = {arXiv},
  eprint    = {1704.07535}
}
% uses LSTM to synthesize ASTs from natural language

@inproceedings{shen2019using,
  title={Using active learning to synthesize models of applications that access databases},
  author={Shen, Jiasi and Rinard, Martin C},
  editor={},
  booktitle={Proceedings of the 40th ACM SIGPLAN Conference on Programming Language Design and Implementation},
  pages={269--285},
  year={2019},
  doi={10.1145/3314221.3314591},
  organization={ACM}
}

@article{shi2019frangel,
  title={FrAngel: component-based synthesis with control structures},
  author={Shi, Kensen and Steinhardt, Jacob and Liang, Percy},
  journal={Proceedings of the ACM on Programming Languages},
  volume={3},
  number={POPL},
  pages={73},
  year={2019},
  doi={10.1145/3290386},
  url = {https://dl.acm.org/doi/abs/10.1145/3290386}
}

@online{architecture,
  title = {Program synthesis for declarative building design},
  author = {Andrew Zukoski and
            Drew Wolpert},
  year = {2017},
  month = {Sep},
  url = {https://youtu.be/yJW--wNMv1M},
  urldate = {2019-12-16}
}

@article{lenses,
  title={Synthesizing bijective lenses},
  author={Miltner, Anders and
          Fisher, Kathleen and
          Pierce, Benjamin C and
          Walker, David and
          Zdancewic, Steve},
  journal={Proceedings of the ACM on Programming Languages},
  volume={2},
  number={POPL},
  pages={1},
  doi={10.1145/3158089},
  url={https://dl.acm.org/doi/abs/10.1145/3158089},
  year={2017}
}

@article{neuralmachinetranslation,
  author    = {Taro Sekiyama and
                Akifumi Imanishi and
                Kohei Suenaga},
  title     = {Towards Proof Synthesis Guided by Neural Machine Translation for Intuitionistic Propositional Logic},
  journal   = {CoRR},
  volume    = {abs/1706.06462},
  year      = {2017},
  url       = {http://arxiv.org/abs/1706.06462},
  archivePrefix = {arXiv},
  eprint    = {1706.06462}
}

% the paper is type-based, not by itself using examples.
% source={https://github.com/hazelgrove/hazelnut-dynamics-agda},
article{omar2019live,
  title={Live functional programming with typed holes},
  author={Omar, Cyrus and
          Voysey, Ian and
          Chugh, Ravi and
          Hammer, Matthew A},
  journal={Proceedings of the ACM on Programming Languages},
  volume={3},
  number={POPL},
  pages={14},
  year={2019},
  doi={10.1145/3290327},
  url={https://arxiv.org/abs/1805.00155}
}
% followup-source={https://github.com/hazelgrove/hazelnut-myth-agda},
% "the mechanization of our ongoing work on type+example synthesis with big-step hazelnut dynamics."
% the code looks as abstract as the paper -- I don't see anything about examples though, which are not mentioned in the paper either...

@inproceedings{odena2020learning,
  title={Learning to Represent Programs with Property Signatures},
  author={Odena, Augustus and
          Sutton, Charles},
  editor={},
  booktitle={International Conference on Learning Representations},
  year={2020},
  url={https://arxiv.org/abs/2002.09030}
}

article{das5,
  title={A medium-scale distributed system for computer science research: Infrastructure for the long term},
  author={Bal, Henri and
          Epema, Dick and
          de Laat, Cees and
          van Nieuwpoort, Rob and
          Romein, John and
          Seinstra, Frank and
          Snoek, Cees and
          Wijshoff, Harry},
  journal={Computer},
  volume={49},
  number={5},
  pages={54--63},
  year={2016},
  url={https://www.cs.vu.nl/das/das2016.pdf}
}

article{deville1994logic,
  title={Logic program synthesis},
  author={Deville, Yves and
          Lau, Kung-Kiu},
  journal={The Journal of Logic Programming},
  volume={19},
  pages={321--350},
  url={https://core.ac.uk/download/pdf/82617549.pdf},
  year={1994}
}
% There are three main approaches to logic program synthesis by formal methods:
% \item In the constructive approach, a conjecture based on the specification is constructively proved, and from this proof, the specified program is extracted. We call this approach constructive synthesis.
% \item A more direct approach is to deduce clauses for the specified program directly from the specification. We shall call this approach deductive synthesis. Another approach can induce a program from a partial specification of the program.
% \item The program is a generalization of the partial specification. We shall call this approach inductive synthesis.

% out of trace-/model-based I guess NPS is model-based while e.g. Osera's approach seemed more trace-based:
% ~\citep{deville1994logic}: Within the methods for inductive program synthesis, one can distinguish between the trace-based approach and the model-based approach.
% In the trace-based approach, example traces are first generated. A trace is a sequence of instructions executed by an unknown program on some given input data. Then the traces are generalized into a program. This program may be obtained by folding, matching, and generalizing the traces. Generalization is required since traces are related to some specific inputs; folding is required in order to form loops and recursion.
% In the model-based approach, synthesis aims at constructing a finite axiomatization of a model of the examples. It thus makes an intensional representation of a relation (i.e., a program) from the given (incomplete) extensional representation (i.e., the examples). The model-based approach to inductive synthesis of logic program is better known as Inductive Logic Programming (ILP).
% 6.2. Schema-Guided Program Construction: template-based
% basically every node-picking step I do is an instance of this.

@misc{bodik2013algorithmic,
  title={Algorithmic program synthesis: introduction},
  author={Bod{\'\i}k, Rastislav and
          Jobstmann, Barbara},
  year={2013},
  doi={10.1007/s10009-013-0287-9},
  url={https://link.springer.com/article/10.1007/s10009-013-0287-9}
}
% We divide the field into reactive synthesis, which is concerned with automata-theoretic techniques for controllers that handle an infinite stream of requests, and functional synthesis, which produces programs consuming finite input.
% axiomatic synthesizers (improve basic program incrementally by axioms, no partial programs) vs. syntactically derived synthesizers (gradually fill parameterizable template program using a grammar), origins in inductive inference of functions and formal languages from examples.
% Inductive programming Synthesis of programs from incomplete specifications presented as positive and negative examples has been developed for functional programs [92] and logic programs.
% generate-and-test
% mashup of web services: Planning and synthesis techniques have been successfully used to compose web services, e.g., in [10,37].
% RL by synthesis: The programming language aLisp (agent Lisp) by Andre et al. [4,130] was designed for expressing prior knowledge in hierarchical reinforcement learning of agent policies. trains RL agents by expanding on an existing partial program.
% Huynh et al. [82] developed an algorithm that synthesizes [a web scraping] extraction program from user demonstration.

% neural tree transducer (NTT): tree-to-tree learning by top-down depth-first context-sensitive tree decoder paired with recursive neural encoders.
article{sedoc2018neural,
  title={Neural Tree Transducers for Tree to Tree Learning},
  author={Sedoc, Jo{\~a}o and
          Foster, Dean and
          Ungar, Lyle},
  url={https://openreview.net/forum?id=rJBwoM-Cb&noteId=rJBwoM-Cb},
  journaltitle = {Open Review},
  year={2018}
}

% #neural-guided-deductive-search
@article{camacho2019towards,
  title={Towards Neural-Guided Program Synthesis for Linear Temporal Logic Specifications},
  author={Camacho, Alberto and
          McIlraith, Sheila A},
  journal={arXiv preprint arXiv:1912.13430},
  url={https://arxiv.org/abs/1912.13430},
  year={2019}
}
% LTL by RL. synthesize a strategy that reacts to a potentially adversarial environment while ensuring that all executions satisfy a Linear Temporal Logic (LTL) specification.

article{fan2019adaptive,
  title={Adaptive Correlated Monte Carlo for Contextual Categorical Sequence Generation},
  author={Fan, Xinjie and
          Zhang, Yizhe and
          Wang, Zhendong and
          Zhou, Mingyuan},
  journal={arXiv preprint arXiv:1912.13151},
  url={https://arxiv.org/abs/1912.13151},
  year={2019}
}
% adapt to contextual generation of categorical sequences a policy gradient estimator

%article{yin2017syntactic,
%  title={A syntactic neural model for general-purpose code generation},
%  author={Yin, Pengcheng and
%          Neubig, Graham},
%  journal={arXiv preprint arXiv:1704.01696},
%  url={https://arxiv.org/abs/1704.01696},
%  year={2017}
%}
% a novel neural architecture powered by a grammar model to explicitly capture the target syntax as prior knowledge for program synthesis from natural-language input

@article{xu2019neural,
  title={Neural Program Synthesis By Self-Learning},
  author={Xu, Yifan and
          Dai, Lu and
          Singh, Udaikaran and
          Zhang, Kening and
          Tu, Zhuowen},
  journal={arXiv preprint arXiv:1910.05865},
  url={https://arxiv.org/abs/1910.05865},
  year={2019}
}
% neural program synthesis algorithm learned via self-learning RL that explores the large code space efficiently.

%article{young2019learning,
%  title={Learning neurosymbolic generative models via program synthesis},
%  author={Young, Halley and
%          Bastani, Osbert and
%          Naik, Mayur},
%  journal={arXiv preprint arXiv:1901.08565},
%  url={https://arxiv.org/abs/1901.08565},
%  year={2019}
%}
% incorporate programs representing global structure into the generative model

inproceedings{chen2019neural,
  title={Neural Symbolic Reader: Scalable Integration of Distributed and Symbolic Representations for Reading Comprehension},
  author={Chen, Xinyun and
          Liang, Chen and
          Yu, Adams Wei and
          Zhou, Denny and
          Song, Dawn and
          Le, Quoc V},
  editor={},
  booktitle={International Conference on Learning Representations},
  url={https://openreview.net/forum?id=ryxjnREFwH&noteId=ryxjnREFwH},
  year={2019}
}
% Neural Symbolic Reader (NeRd): reader (e.g., BERT) to encode the passage/question + programmer (e.g., LSTM) to generate a program to produce the answer.

@article{chen2017towards,
  title={Towards synthesizing complex programs from input-output examples},
  author={Chen, Xinyun and
          Liu, Chang and
          Song, Dawn},
  journal={arXiv preprint arXiv:1706.01284},
  url={https://arxiv.org/abs/1706.01284},
  year={2017}
}
% new task: learn parser from input + parse trees. tackle by: (1) use non-differentiable machine to restrict search space; (2) recursion; (3) RL to operate the machine.

@inproceedings{shin2019program,
  title={Program synthesis and semantic parsing with learned code idioms},
  author={Shin, Eui Chul and
          Allamanis, Miltiadis and
          Brockschmidt, Marc and
          Polozov, Alex},
  editor={},
  booktitle={Advances in Neural Information Processing Systems},
  pages={10824--10834},
  url={http://papers.nips.cc/paper/9265-program-synthesis-and-semantic-parsing-with-learned-code-idioms},
  year={2019}
}
% Patois: let a neural program synthesizer interleave high-/low-level reasoning by automatically mining common code idioms from a given corpus.

@online{polozov,
  author = {Polozov, Alex},
  title = {Program Synthesis in 2017-18},
  year = {2018},
  month = {Jul},
  url={https://alexpolozov.com/blog/program-synthesis-2018/},
  urldate = {2020-02-23}
}
% Program Synthesis in 2017-18
% Neural-guided search
% Sketch generation
% Graph neural networks
% Datasets
% Notable mentions: differentiable FlashFill, Conflict-Driven Learning, Programmatically Interpretable RL

@article{pirl,
  title={Programmatically interpretable reinforcement learning},
  author={Verma, Abhinav and
          Murali, Vijayaraghavan and
          Singh, Rishabh and
          Kohli, Pushmeet and
          Chaudhuri, Swarat},
  journal={arXiv preprint arXiv:1804.02477},
  url={https://arxiv.org/abs/1804.02477},
  year={2018}
}
% RL by program synthesis for interpretable/verifiable agent policies.
% Neurally Directed Program Search (NDPS): first learn a neural policy network using DRL, then perform a local search over programmatic policies that seeks to minimize a distance from this neural "oracle".

@article{hughes1989functional,
  title={Why functional programming matters},
  author={Hughes, John},
  journal={The computer journal},
  volume={32},
  number={2},
  pages={98--107},
  year={1989},
  url={https://academic.oup.com/comjnl/article/32/2/98/543535},
  publisher={Oxford University Press}
}

@book{koza1994genetic,
  title={Genetic programming II},
  author={Koza, John R and
          others},
  volume={17},
  year={1994},
  url={https://amazon.com/s?k=9780262111706},
  publisher={MIT press Cambridge}
}

@article{allamanis2017learning,
  title={Learning to represent programs with graphs},
  author={Allamanis, Miltiadis and
          Brockschmidt, Marc and
          Khademi, Mahmoud},
  journal={arXiv preprint arXiv:1711.00740},
  url={https://arxiv.org/abs/1711.00740},
  year={2017}
}

@article{brockschmidt2018generative,
  title={Generative code modeling with graphs},
  author={Brockschmidt, Marc and
          Allamanis, Miltiadis and
          Gaunt, Alexander L and
          Polozov, Oleksandr},
  journal={arXiv preprint arXiv:1805.08490},
  url={https://arxiv.org/abs/1805.08490},
  year={2018}
}

@inproceedings{looks2005learning,
  title={Learning computer programs with the bayesian optimization algorithm},
  author={Looks, Moshe and
          Goertzel, Ben and
          Pennachin, Cassio},
  booktitle={Proceedings of the 7th annual conference on Genetic and evolutionary computation},
  pages={747--748},
  doi={10.1145/1068009.1068134},
  url={https://dl.acm.org/doi/abs/10.1145/1068009.1068134},
  year={2005}
}

@article{verma2018programmatically,
  title={Programmatically interpretable reinforcement learning},
  author={Verma, Abhinav and
          Murali, Vijayaraghavan and
          Singh, Rishabh and
          Kohli, Pushmeet and
          Chaudhuri, Swarat},
  journal={arXiv preprint arXiv:1804.02477},
  url={https://arxiv.org/abs/1804.02477},
  year={2018}
}

@article{akiba2013calibrating,
  title={Calibrating research in program synthesis using 72,000 hours of programmer time},
  author={Akiba, Takuya and
          Imajo, Kentaro and
          Iwami, Hiroaki and
          Iwata, Yoichi and
          Kataoka, Toshiki and
          Takahashi, Naohiro and
          Moskal, Micha{\l} and
          Swamy, Nikhil},
  journal={MSR, Redmond, WA, USA, Tech. Rep},
  url={https://pdfs.semanticscholar.org/1cde/a6fa2f0a400f509aed98f9a857ab1788257e.pdf},
  year={2013}
}

@book{alur2013syntax,
  title={Syntax-guided synthesis},
  author={Alur, Rajeev and
          Bodik, Rastislav and
          Juniwal, Garvit and
          Martin, Milo MK and
          Raghothaman, Mukund and
          Seshia, Sanjit A and
          Singh, Rishabh and
          Solar-Lezama, Armando and
          Torlak, Emina and
          Udupa, Abhishek},
  year={2013},
  doi={10.1109/FMCAD.2013.6679385},
  url={https://ieeexplore.ieee.org/abstract/document/6679385},
  publisher={IEEE}
}

@article{alur2016sygus,
  title={Sygus-comp 2016: results and analysis},
  author={Alur, Rajeev and
          Fisman, Dana and
          Singh, Rishabh and
          Solar-Lezama, Armando},
  journal={arXiv preprint arXiv:1611.07627},
  url={https://arxiv.org/abs/1611.07627},
  year={2016}
}

@inproceedings{singh2015predicting,
  title={Predicting a correct program in programming by example},
  author={Singh, Rishabh and
          Gulwani, Sumit},
  booktitle={International Conference on Computer Aided Verification},
  pages={398--414},
  year={2015},
  doi={10.1007/978-3-319-21690-4_23},
  url={https://doi.org/10.1007/978-3-319-21690-4_23},
  organization={Springer}
}

@book{solar2008program,
  title={Program synthesis by sketching},
  author={Solar-Lezama, Armando and
          Bodik, Rastislav},
  year={2008},
  doi={10.5555/1714168},
  url={http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.207.9048&rep=rep1&type=pdf},
  publisher={Citeseer}
}

@article{feng2018program,
  title={Program synthesis using conflict-driven learning},
  author={Feng, Yu and
          Martins, Ruben and
          Bastani, Osbert and
          Dillig, Isil},
  journal={ACM SIGPLAN Notices},
  volume={53},
  number={4},
  pages={420--435},
  year={2018},
  doi={10.1145/3296979.3192382},
  url={https://dl.acm.org/doi/abs/10.1145/3296979.3192382},
  publisher={ACM New York, NY, USA}
}
% top-down, SMT + conflict-driven. if output list length doesn't correspond with `map`, also rule out `reverse` and `sort`. sounds crazy smart! neural ordering like NSPS could maybe hook in as their `decide` function.

@article{prose,
  title={Automating string processing in spreadsheets using input-output examples},
  author={Gulwani, Sumit},
  journal={ACM Sigplan Notices},
  volume={46},
  number={1},
  pages={317--330},
  year={2011},
  doi={10.1145/1925844.1926423},
  url={https://dl.acm.org/doi/abs/10.1145/1925844.1926423},
  publisher={ACM New York, NY, USA}
}
% see notes on prose framework up at kalyan2018neural

@article{neuralgpu,
  title={Neural gpus learn algorithms},
  author={Kaiser, {\L}ukasz and
          Sutskever, Ilya},
  journal={arXiv preprint arXiv:1511.08228},
  url={https://arxiv.org/abs/1511.08228},
  year={2015}
}

@article{nmt,
  title={Neural machine translation by jointly learning to align and translate},
  author={Bahdanau, Dzmitry and
          Cho, Kyunghyun and
          Bengio, Yoshua},
  journal={arXiv preprint arXiv:1409.0473},
  url={https://arxiv.org/abs/1409.0473},
  year={2014}
}

@inproceedings{ptrnets,
  title={Pointer networks},
  author={Vinyals, Oriol and
          Fortunato, Meire and
          Jaitly, Navdeep},
  booktitle={Advances in neural information processing systems},
  pages={2692--2700},
  url={http://papers.nips.cc/paper/5866-pointer-networks},
  year={2015}
}

@article{structuredattention,
  title={Structured attention networks},
  author={Kim, Yoon and
          Denton, Carl and
          Hoang, Luong and
          Rush, Alexander M},
  journal={arXiv preprint arXiv:1702.00887},
  url={https://arxiv.org/abs/1702.00887},
  year={2017}
}

@article{ntm,
  title={Neural turing machines},
  author={Graves, Alex and
          Wayne, Greg and
          Danihelka, Ivo},
  journal={arXiv preprint arXiv:1410.5401},
  url={https://arxiv.org/abs/1410.5401},
  year={2014}
}

@article{neuralram,
  title={Neural random-access machines},
  author={Kurach, Karol and
          Andrychowicz, Marcin and
          Sutskever, Ilya},
  journal={arXiv preprint arXiv:1511.06392},
  url={https://arxiv.org/abs/1511.06392},
  year={2015}
}

@article{neuralprogrammer,
  title={Neural programmer: Inducing latent programs with gradient descent},
  author={Neelakantan, Arvind and
          Le, Quoc V and
          Sutskever, Ilya},
  journal={arXiv preprint arXiv:1511.04834},
  url={https://arxiv.org/abs/1511.04834},
  year={2015}
}

@article{hierarchicalmemory,
  title={Learning efficient algorithms with hierarchical attentive memory},
  author={Andrychowicz, Marcin and
          Kurach, Karol},
  journal={arXiv preprint arXiv:1602.03218},
  url={https://arxiv.org/abs/1602.03218},
  year={2016}
}

@article{npl,
  title={Neural program lattices},
  author={Li, Chengtao and
          Tarlow, Daniel and
          Gaunt, Alexander L and
          Brockschmidt, Marc and
          Kushman, Nate},
  url={https://openreview.net/forum?id=HJjiFK5gx},
  year={2016}
}

@article{cai2017making,
  title={Making neural programming architectures generalize via recursion},
  author={Cai, Jonathon and
          Shin, Richard and
          Song, Dawn},
  journal={arXiv preprint arXiv:1704.06611},
  url={https://arxiv.org/abs/1704.06611},
  year={2017}
}

article{vedantam2019probabilistic,
  title={Probabilistic neural-symbolic models for interpretable visual question answering},
  author={Vedantam, Ramakrishna and
          Desai, Karan and
          Lee, Stefan and
          Rohrbach, Marcus and
          Batra, Dhruv and
          Parikh, Devi},
  journal={arXiv preprint arXiv:1902.07864},
  url={https://arxiv.org/abs/1902.07864},
  year={2019}
}

article{treelstm,
  title={Improved semantic representations from tree-structured long short-term memory networks},
  author={Tai, Kai Sheng and
          Socher, Richard and
          Manning, Christopher D},
  journal={arXiv preprint arXiv:1503.00075},
  url={https://arxiv.org/pdf/1503.00075.pdf},
  year={2015}
}

% use RL (Reinforce) to provide a seq2seq neural programmer with a differentiable signal on the evaluation of a Q&A task
@article{nsm,
  title={Neural symbolic machines: Learning semantic parsers on freebase with weak supervision},
  author={Liang, Chen and
          Berant, Jonathan and
          Le, Quoc and
          Forbus, Kenneth D and
          Lao, Ni},
  journal={arXiv preprint arXiv:1611.00020},
  url={https://arxiv.org/abs/1611.00020},
  year={2016}
}

% like NSM but with memory-augmented RL, has code, beat some w/ strong supervision
@incollection{mapo,
  title = {Memory Augmented Policy Optimization for Program Synthesis and Semantic Parsing},
  author = {Liang, Chen and
            Norouzi, Mohammad and
            Berant, Jonathan and
            Le, Quoc V and
            Lao, Ni},
  booktitle = {Advances in Neural Information Processing Systems 31},
  editor = {S. Bengio and
            H. Wallach and
            H. Larochelle and
            K. Grauman and
            N. Cesa-Bianchi and
            R. Garnett},
  pages = {9994--10006},
  year = {2018},
  publisher = {Curran Associates, Inc.},
  url = {http://papers.nips.cc/paper/8204-memory-augmented-policy-optimization-for-program-synthesis-and-semantic-parsing.pdf}
}

@article{muggleton1991inductive,
  title={Inductive logic programming},
  author={Muggleton, Stephen},
  journal={New generation computing},
  volume={8},
  number={4},
  pages={295--318},
  year={1991},
  doi={10.1007/BF03037089},
  publisher={Springer}
}

@article{lisp,
  author = {Summers, Phillip D.},
  title = {A Methodology for LISP Program Construction from Examples},
  year = {1977},
  issue_date = {Jan. 1977},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {24},
  number = {1},
  issn = {0004-5411},
  url = {https://doi.org/10.1145/321992.322002},
  doi = {10.1145/321992.322002},
  journal = {J. ACM},
  month = jan,
  pages = {161–175},
  numpages = {15}
}

@article{fogel1966intelligent,
  title={Intelligent decision making through a simulation of evolution},
  author={Fogel, Lawrence J and Owens, Alvin J and Walsh, Michael J},
  journal={Behavioral science},
  volume={11},
  number={4},
  pages={253--272},
  year={1966},
  publisher={Wiley Online Library}
}

@misc{popplestone1969experiment,
  title={An experiment in automatic induction. Machine Intelligence 5},
  author={Popplestone, RJ},
  year={1969},
  url={https://aitopics.org/download/classics:0B2939E6},
  publisher={Edinburgh: Edinburgh University Press}
}

@article{plotkin1970note,
  title={A note on inductive generalization},
  author={Plotkin, Gordon D},
  journal={Machine intelligence},
  volume={5},
  number={1},
  pages={153--163},
  url={http://homepages.inf.ed.ac.uk/gdp/publications/MI5_note_ind_gen.pdf},
  year={1970}
}

@article{russell2002artificial,
  title={Artificial intelligence: a modern approach},
  author={Russell, Stuart and Norvig, Peter},
  url={https://people.eecs.berkeley.edu/~russell/aima1e.html},
  year={2002}
}

@article{hierarchicalrl,
  title={Recent advances in hierarchical reinforcement learning},
  author={Barto, Andrew G and
          Mahadevan, Sridhar},
  journal={Discrete event dynamic systems},
  volume={13},
  number={1-2},
  pages={41--77},
  year={2003},
  doi={10.1023/A:1022140919877},
  url={https://link.springer.com/article/10.1023/A:1022140919877},
  publisher={Springer}
}

@article{burstall1977design,
  title={Design considerations for a functional programming language},
  author={Burstall, Rod M},
  journal={The software revolution},
  year={1977}
}

@article{dybjer1991logical,
  title={Logical Frameworks: Inductive sets and families in Martin-L{\"o}f's type theory and their set-theoretic semantics},
  author={Dybjer, Peter},
  year={1991}
}

@phdthesis{blott1991type,
  title={Type classes},
  author={Blott, Stephen},
  year={1991},
  school={PhD thesis, Department of Computing Science, Glasgow University}
}

@inproceedings{haskellhistory,
  author = {Hudak, Paul and Hughes, John and Peyton Jones, Simon and Wadler, Philip},
  title = {A History of Haskell: Being Lazy with Class},
  year = {2007},
  isbn = {9781595937667},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/1238844.1238856},
  doi = {10.1145/1238844.1238856},
  booktitle = {Proceedings of the Third ACM SIGPLAN Conference on History of Programming Languages},
  pages = {12–1–12–55},
  numpages = {55},
  location = {San Diego, California},
  series = {HOPL III}
}

@article{backproprnn,
  title={Learning representations by back-propagating errors},
  author={Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J},
  journal={nature},
  volume={323},
  number={6088},
  pages={533--536},
  year={1986},
  publisher={Nature Publishing Group}
}

@article{lstm,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}

@article{lee2018accelerating,
  title={Accelerating search-based program synthesis using learned probabilistic models},
  author={Lee, Woosuk and
          Heo, Kihong and
          Alur, Rajeev and
          Naik, Mayur},
  journal={ACM SIGPLAN Notices},
  volume={53},
  number={4},
  pages={436--449},
  year={2018},
  url={https://www.cis.upenn.edu/~alur/PLDI18.pdf},
  publisher={ACM New York, NY, USA}
}
% top-down, A* (order by estimated distance from goal), SyGuS, probabilistic higher order grammar (PHOG)

@article{zhang2018leveraging,
  title={Leveraging constraint logic programming for neural guided program synthesis},
  author={Zhang, Lisa and
          Rosenblatt, Gregory and
          Fetaya, Ethan and
          Liao, Renjie and
          Byrd, William E and
          Urtasun, Raquel and
          Zemel, Richard},
  url={https://openreview.net/pdf?id=HJIHtIJvz},
  year={2018}
}
% miniKanren builds constraints per rule; embed -> score -> pick. deductive so propagates constraints.

@article{polosukhin2018neural,
  title={Neural program search: Solving programming tasks from description and examples},
  author={Polosukhin, Illia and
          Skidanov, Alexander},
  journal={arXiv preprint arXiv:1802.04335},
  url={https://arxiv.org/abs/1802.04335},
  year={2018}
}
% synthesis from description + examples; offers pseudo-code for tree-beam search

@online{hasktorch,
  author={Huang, Austin and
          Stites, Sam and
          Hashimoto, Junji and
          Scholak, Torsten and
          Paszke, Adam and
          others},
  title={HaskTorch: Tensors and neural networks in Haskell},
  year={2017},
  month={Sep},
  url={https://github.com/hasktorch/hasktorch},
  urldate={2020-05-13}
}

@article{murali2017neural,
  title={Neural sketch learning for conditional program generation},
  author={Murali, Vijayaraghavan and
          Qi, Letao and
          Chaudhuri, Swarat and
          Jermaine, Chris},
  journal={arXiv preprint arXiv:1703.05698},
  url={https://arxiv.org/abs/1703.05698},
  year={2017}
}

@article{shuman2013emerging,
  title={The emerging field of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains},
  author={Shuman, David I and
          Narang, Sunil K and
          Frossard, Pascal and
          Ortega, Antonio and
          Vandergheynst, Pierre},
  journal={IEEE signal processing magazine},
  volume={30},
  number={3},
  pages={83--98},
  year={2013},
  url={https://arxiv.org/abs/1211.0053},
  publisher={IEEE}
}

@article{wu2020comprehensive,
  title={A comprehensive survey on graph neural networks},
  author={Wu, Zonghan and
          Pan, Shirui and
          Chen, Fengwen and
          Long, Guodong and
          Zhang, Chengqi and
          Philip, S Yu},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  year={2020},
  url={https://arxiv.org/abs/1901.00596},
  publisher={IEEE}
}

@article{multitasklearning,
  author    = {Sebastian Ruder},
  title     = {An Overview of Multi-Task Learning in Deep Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1706.05098},
  year      = {2017},
  url       = {http://arxiv.org/abs/1706.05098},
  archivePrefix = {arXiv},
  eprint    = {1706.05098},
  timestamp = {Mon, 13 Aug 2018 16:48:50 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/Ruder17a.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{pan2009survey,
  title={A survey on transfer learning},
  author={Pan, Sinno Jialin and
          Yang, Qiang},
  journal={IEEE Transactions on knowledge and data engineering},
  volume={22},
  number={10},
  pages={1345--1359},
  year={2009},
  doi={10.1109/TKDE.2009.191},
  url={https://doi.org/10.1109/TKDE.2009.191},
  publisher={IEEE}
}

@article{zhong2017seq2sql,
  title={Seq2sql: Generating structured queries from natural language using reinforcement learning},
  author={Zhong, Victor and
          Xiong, Caiming and
          Socher, Richard},
  journal={arXiv preprint arXiv:1709.00103},
  url={https://arxiv.org/abs/1709.00103},
  year={2017}
}

@article{koskimies1994automatic,
  title={Automatic synthesis of state machines from trace diagrams},
  author={Koskimies, Kai and
          M{\"a}kinen, Erkki},
  journal={Software: Practice and Experience},
  volume={24},
  number={7},
  pages={643--658},
  year={1994},
  doi={10.1002/spe.4380240704},
  url={https://doi.org/10.1002/spe.4380240704},
  publisher={Wiley Online Library}
}

@inproceedings{demsky2006inference,
  title={Inference and enforcement of data structure consistency specifications},
  author={Demsky, Brian and
          Ernst, Michael D and
          Guo, Philip J and
          McCamant, Stephen and
          Perkins, Jeff H and
          Rinard, Martin},
  booktitle={Proceedings of the 2006 international symposium on Software testing and analysis},
  pages={233--244},
  doi={10.1145/1146238.1146266},
  url={https://doi.org/10.1145/1146238.1146266},
  year={2006}
}

@inproceedings{kaleeswaran2014minthint,
  title={Minthint: Automated synthesis of repair hints},
  author={Kaleeswaran, Shalini and
          Tulsian, Varun and
          Kanade, Aditya and
          Orso, Alessandro},
  booktitle={Proceedings of the 36th International Conference on Software Engineering},
  pages={266--276},
  url={https://dl.acm.org/doi/pdf/10.1145/2568225.2568258},
  doi={10.1145/2568225.2568258},
  year={2014}
}

@article{louridas2006static,
  title={Static code analysis},
  author={Louridas, Panagiotis},
  journal={Ieee Software},
  volume={23},
  number={4},
  pages={58--61},
  year={2006},
  url={https://doi.org/10.1109/MS.2006.114},
  doi={10.1109/MS.2006.114},
  publisher={IEEE}
}

@article{albrecht1980source,
  title={Source-to-source translation: Ada to Pascal and Pascal to Ada},
  author={Albrecht, Paul F and
          Garrison, Philip E and
          Graham, Susan L and
          Hyerle, Robert H and
          Ip, Patricia and
          Krieg-Br{\"u}ckner, Bernd},
  journal={ACM SIGPLAN Notices},
  volume={15},
  number={11},
  pages={183--193},
  year={1980},
  url={https://doi.org/10.1145/947783.948658},
  doi={10.1145/947783.948658},
  publisher={ACM New York, NY, USA}
}

@article{loveman1977program,
  title={Program improvement by source-to-source transformation},
  author={Loveman, David B},
  journal={Journal of the ACM (JACM)},
  volume={24},
  number={1},
  pages={121--145},
  year={1977},
  url={https://doi.org/10.1145/321992.322000},
  doi={10.1145/321992.322000},
  publisher={ACM New York, NY, USA}
}

@article{czarnecki2006feature,
  title={Feature-based survey of model transformation approaches},
  author={Czarnecki, Krzysztof and
          Helsen, Simon},
  journal={IBM Systems Journal},
  volume={45},
  number={3},
  pages={621--645},
  year={2006},
  url={https://doi.org/10.1147/sj.453.0621},
  doi={10.1147/sj.453.0621},
  publisher={IBM}
}

@article{visser2005survey,
  title={A survey of strategies in rule-based program transformation systems},
  author={Visser, Eelco},
  journal={Journal of symbolic computation},
  volume={40},
  number={1},
  pages={831--873},
  year={2005},
  url={https://doi.org/10.1016/j.jsc.2004.12.011},
  doi={10.1016/j.jsc.2004.12.011},
  publisher={Elsevier}
}

@article{partsch1983program,
  title={Program transformation systems},
  author={Partsch, Helmuth and
          Steinbr{\"u}ggen, Ralf},
  journal={ACM Computing Surveys (CSUR)},
  volume={15},
  number={3},
  pages={199--236},
  year={1983},
  url={https://doi.org/10.1145/356914.356917},
  doi={10.1145/356914.356917},
  publisher={ACM New York, NY, USA}
}

@article{waters1988program,
  title={Program translation via abstraction and reimplementation},
  author={Waters, Richard C},
  journal={IEEE Transactions on Software Engineering},
  volume={14},
  number={8},
  pages={1207--1228},
  year={1988},
  url={https://doi.org/10.1109/32.7629},
  doi={doi.org/10.1109/32.7629},
  publisher={IEEE}
}

@incollection{chen2018tree,
  title = {Tree-to-tree Neural Networks for Program Translation},
  author = {Chen, Xinyun and
            Liu, Chang and
            Song, Dawn},
  booktitle = {Advances in Neural Information Processing Systems 31},
  editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
  pages = {2547--2557},
  year = {2018},
  publisher = {Curran Associates, Inc.},
  url = {http://papers.nips.cc/paper/7521-tree-to-tree-neural-networks-for-program-translation.pdf}
}

@inproceedings{kim2019translating,
  title={Translating CUDA to OpenCL for hardware generation using neural machine translation},
  author={Kim, Yonghae and
          Kim, Hyesoon},
  booktitle={2019 IEEE/ACM International Symposium on Code Generation and Optimization (CGO)},
  pages={285--286},
  year={2019},
  url={https://doi.org/10.1109/CGO.2019.8661172},
  doi={10.1109/CGO.2019.8661172},
  organization={IEEE}
}

@article{cho2014nmt,
  author    = {KyungHyun Cho and
               Bart van Merrienboer and
               Dzmitry Bahdanau and
               Yoshua Bengio},
  title     = {On the Properties of Neural Machine Translation: Encoder-Decoder Approaches},
  journal   = {CoRR},
  volume    = {abs/1409.1259},
  year      = {2014},
  url       = {http://arxiv.org/abs/1409.1259},
  archivePrefix = {arXiv},
  eprint    = {1409.1259},
  timestamp = {Mon, 13 Aug 2018 16:47:23 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/ChoMBB14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{virtualassistant,
  author={Tulshan, Amrita S. and
          Dhage, Sudhir Namdeorao},
  editor={Thampi, Sabu M. and
          Marques, Oge and
          Krishnan, Sri and
          Li, Kuan-Ching and
          Ciuonzo, Domenico and
          Kolekar, Maheshkumar H.},
  title={Survey on Virtual Assistant: Google Assistant, Siri, Cortana, Alexa},
  booktitle={Advances in Signal Processing and Intelligent Recognition Systems},
  year={2019},
  publisher={Springer Singapore},
  address={Singapore},
  pages={190--201},
  url={https://doi.org/10.1109/msp.2016.2617341},
  doi={10.1109/msp.2016.2617341},
  abstract={Virtual assistant is boon for everyone in this new era of 21st century. It has paved way for a new technology where we can ask questions to machine and can interact with IVAs as people do with humans. This new technology attracted almost whole world in many ways like smart phones, laptops, computers etc. Some of the significant VPs are like Siri, Google Assistant, Cortana, and Alexa. Voice recognition, contextual understanding and human interaction are the issues which are not solved yet in this IVAs. So, to solve those issues 100 users participated a survey for this research and shared their experiences. All users' task was to ask questions from the survey to all personal assistants and from their experiences this research paper came up with the actual results. According to that results many services were covered by these assistants but still there are some improvements required in voice recognition, contextual understanding and hand free interaction. After addressing these improvements in IVAs will definitely increased its use is the main goal for this research paper.},
  isbn={978-981-13-5758-9}
}

@article{genie,
  author    = {Giovanni Campagna and
               Silei Xu and
               Mehrad Moradshahi and
               Richard Socher and
               Monica S. Lam},
  title     = {Genie: {A} Generator of Natural Language Semantic Parsers for Virtual
               Assistant Commands},
  journal   = {CoRR},
  volume    = {abs/1904.09020},
  year      = {2019},
  url       = {http://arxiv.org/abs/1904.09020},
  archivePrefix = {arXiv},
  eprint    = {1904.09020},
  timestamp = {Fri, 26 Apr 2019 13:18:53 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1904-09020.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{juang1991hidden,
  title={Hidden Markov models for speech recognition},
  author={Juang, Biing Hwang and Rabiner, Laurence R},
  journal={Technometrics},
  volume={33},
  number={3},
  pages={251--272},
  year={1991},
  doi={https://www.tandfonline.com/doi/abs/10.1080/00401706.1991.10484833},
  publisher={Taylor \& Francis}
}

@inproceedings{graves2013speech,
  title={Speech recognition with deep recurrent neural networks},
  author={Graves, Alex and Mohamed, Abdel-rahman and Hinton, Geoffrey},
  booktitle={2013 IEEE international conference on acoustics, speech and signal processing},
  pages={6645--6649},
  year={2013},
  url={https://doi.org/10.1109/ICASSP.2013.6638947},
  doi={10.1109/ICASSP.2013.6638947},
  organization={IEEE}
}

@article{li2016deep,
  author    = {Jiwei Li and
               Will Monroe and
               Alan Ritter and
               Michel Galley and
               Jianfeng Gao and
               Dan Jurafsky},
  title     = {Deep Reinforcement Learning for Dialogue Generation},
  journal   = {CoRR},
  volume    = {abs/1606.01541},
  year      = {2016},
  url       = {http://arxiv.org/abs/1606.01541},
  archivePrefix = {arXiv},
  eprint    = {1606.01541},
  timestamp = {Mon, 13 Aug 2018 16:48:20 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/LiMRGGJ16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{bordes2016goaldialogue,
  author    = {Bordes, Antoine and
               Weston, Jason},
  title     = {Learning End-to-End Goal-Oriented Dialog},
  journal   = {CoRR},
  volume    = {abs/1605.07683},
  year      = {2016},
  url       = {http://arxiv.org/abs/1605.07683},
  archivePrefix = {arXiv},
  eprint    = {1605.07683},
  timestamp = {Mon, 13 Aug 2018 16:45:59 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/BordesW16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{li2016taskdialogue,
  author    = {Li, Xiujun and
               Lipton, Zachary C. and
               Dhingra, Bhuwan and
               Li, Lihong and
               Gao, Jianfeng and
               Chen, Yun{-}Nung},
  title     = {A User Simulator for Task-Completion Dialogues},
  journal   = {CoRR},
  volume    = {abs/1612.05688},
  year      = {2016},
  url       = {http://arxiv.org/abs/1612.05688},
  archivePrefix = {arXiv},
  eprint    = {1612.05688},
  timestamp = {Mon, 13 Aug 2018 16:47:16 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/LiLDLGC16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{eiben2003introduction,
  title={Introduction to evolutionary computing},
  author={Eiben, Agoston E and
          Smith, James E and others},
  volume={53},
  year={2003},
  url={https://link.springer.com/book/10.1007/978-3-662-44874-8},
  doi={10.1007/978-3-662-44874-8},
  publisher={Springer}
}

@techreport{settles2009active,
  title={Active learning literature survey},
  author={Settles, Burr},
  year={2009},
  url={http://burrsettles.com/pub/settles.activelearning.pdf},
  institution={University of Wisconsin-Madison Department of Computer Sciences}
}

@book{mockus2012bayesian,
  title={Bayesian approach to global optimization: theory and applications},
  author={Mockus, Jonas},
  volume={37},
  year={2012},
  url={https://books.google.com/books?id=VuKoCAAAQBAJ},
  publisher={Springer Science \& Business Media}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and
          Dong, Wei and
          Socher, Richard and
          Li, Li-Jia and
          Li, Kai and
          Li, Fei-Fei},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  url={https://doi.org/10.1109/CVPR.2009.5206848},
  doi={10.1109/CVPR.2009.5206848},
  organization={Ieee}
}

@article{schkufza2016stochastic,
  title={Stochastic program optimization},
  author={Schkufza, Eric and Sharma, Rahul and Aiken, Alex},
  journal={Communications of the ACM},
  volume={59},
  number={2},
  pages={114--122},
  year={2016},
  url={https://doi.org/10.1145/2863701},
  doi={10.1145/2863701},
  publisher={ACM New York, NY, USA}
}

@inproceedings{weimer2009automatically,
  title={Automatically finding patches using genetic programming},
  author={Weimer, Westley and Nguyen, ThanhVu and Le Goues, Claire and Forrest, Stephanie},
  booktitle={2009 IEEE 31st International Conference on Software Engineering},
  pages={364--374},
  year={2009},
  url={https://solar.fricke.co.uk/Teaching/CS523_2013Spring/Presentations/GenProg.pdf},
  organization={IEEE}
}

@inproceedings{forrest2009genetic,
  title={A genetic programming approach to automated software repair},
  author={Forrest, Stephanie and Nguyen, ThanhVu and Weimer, Westley and Le Goues, Claire},
  booktitle={Proceedings of the 11th Annual conference on Genetic and evolutionary computation},
  pages={947--954},
  doi={10.1145/1569901.1570031},
  url={https://doi.org/10.1145/1569901.1570031},
  year={2009}
}

@inproceedings{devlin2017robustfill,
  title={Robustfill: Neural program learning under noisy i/o},
  author={Devlin, Jacob and
          Uesato, Jonathan and
          Bhupatiraju, Surya and
          Singh, Rishabh and
          Mohamed, Abdel-rahman and
          Kohli, Pushmeet},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={990--998},
  year={2017},
  doi={10.5555/3305381.3305484},
  url={https://doi.org/10.5555/3305381.3305484},
  organization={JMLR. org}
}

@techreport{rosenblatt1961principles,
  title={Principles of neurodynamics. perceptrons and the theory of brain mechanisms},
  author={Rosenblatt, Frank},
  year={1961},
  url={https://apps.dtic.mil/docs/citations/AD0256582},
  institution={Cornell Aeronautical Lab Inc Buffalo NY}  
}

@book{bracewell1986fourier,
  title={The Fourier transform and its applications},
  author={Bracewell, Ronald Newbold and Bracewell, Ronald N},
  volume={31999},
  year={1986},
  url={https://www.academia.edu/download/44001876/34957138.pdf},
  publisher={McGraw-Hill New York}
}

@online{sygus,
  author = {Padh, Saswat},
  title = {Syntax-Guided Synthesis competition (SyGuS-Comp)},
  year = {2014},
  url={https://sygus.org/},
  urldate = {2020-05-18}
}

@article{eilenberg1945general,
  title={General theory of natural equivalences},
  author={Eilenberg, Samuel and
          MacLane, Saunders},
  journal={Transactions of the American Mathematical Society},
  volume={58},
  number={2},
  pages={231--294},
  year={1945},
  url={https://doi.org/10.1090/S0002-9947-1945-0013131-6},
  doi={10.1090/S0002-9947-1945-0013131-6},
  publisher={JSTOR}
}

@book{awodey2010category,
  title={Category theory},
  author={Awodey, Steve},
  year={2010},
  url={https://books.google.com/books?id=UCgUDAAAQBAJ},
  publisher={Oxford University Press}
}

@online{holesagda,
  title = {Quick Guide to Editing, Type Checking and Compiling Agda Code},
  url={https://agda.readthedocs.io/en/latest/getting-started/quick-guide.html},
  urldate = {2020-05-18}
}

@online{holesidris,
  title = {Types and Functions - Idris 1.3.2 documentation},
  url={http://docs.idris-lang.org/en/latest/tutorial/typesfuns.html#holes},
  urldate = {2020-05-18}
}

@online{holeshaskell,
  title = {GHC/Typed holes - HaskellWiki},
  url={https://wiki.haskell.org/GHC/Typed_holes},
  urldate = {2020-05-18}
}

@online{typedrivendev,
  title = {Manning | Type-Driven Development with Idris},
  url={https://manning.com/books/type-driven-development-with-idris},
  urldate = {2020-05-18}
}

@article{mitchell1982generalization,
  title={Generalization as search},
  author={Mitchell, Tom M},
  journal={Artificial intelligence},
  volume={18},
  number={2},
  pages={203--226},
  year={1982},
  url={https://doi.org/10.1016/0004-3702(82)90040-6},
  doi={10.1016/0004-3702(82)90040-6},
  publisher={Elsevier}
}

article{rossum1995python,
  title={Python reference manual},
  author={van Rossum, Guido},
  year={1995},
  doi={10.5555/869369},
  url={https://dl.acm.org/doi/book/10.5555/869369},
  publisher={CWI (Centre for Mathematics and Computer Science)}
}

book{mckinney2012python,
  title={Python for data analysis: Data wrangling with Pandas, NumPy, and IPython},
  author={McKinney, Wes},
  year={2012},
  url={https://books.google.com/books?id=v3n4_AK8vu0C},
  publisher={"O'Reilly Media, Inc."}
}

article{lawson1979basic,
  title={Basic linear algebra subprograms for Fortran usage},
  author={Lawson, Chuck L and
          Hanson, Richard J. and
          Kincaid, David R and
          Krogh, Fred T.},
  journal={ACM Transactions on Mathematical Software (TOMS)},
  volume={5},
  number={3},
  pages={308--323},
  year={1979},
  url={https://dl.acm.org/doi/pdf/10.1145/355841.355847},
  doi={10.1145/355841.355847},
  publisher={ACM New York, NY, USA}
}

book{oliphant2006guide,
  title={A guide to NumPy},
  author={Oliphant, Travis E},
  volume={1},
  year={2006},
  url={https://ecs.wgtn.ac.nz/foswiki/pub/Support/ManualPagesAndDocumentation/numpybook.pdf},
  publisher={Trelgol Publishing USA}
}

@inproceedings{miller2018smart,
  title={Smart contracts and opportunities for formal methods},
  author={Miller, Andrew and
          Cai, Zhicheng and
          Jha, Somesh},
  booktitle={International Symposium on Leveraging Applications of Formal Methods},
  pages={280--299},
  year={2018},
  url={https://doi.org/10.1007/978-3-030-03427-6_22},
  doi={10.1007/978-3-030-03427-6_22},
  organization={Springer}
}

@inproceedings{leveson2001systemic,
  title={Systemic factors in software-related spacecraft accidents},
  author={Leveson, Nancy},
  booktitle={AIAA Space 2001 Conference and Exposition},
  pages={4763},
  url={http://sunnyday.mit.edu/accidents/space2001-version2.pdf},
  doi={10.2514/6.2001-4763},
  year={2001}
}

article{neidinger2010introduction,
  title={Introduction to automatic differentiation and MATLAB object-oriented programming},
  author={Neidinger, Richard D},
  journal={SIAM review},
  volume={52},
  number={3},
  pages={545--563},
  year={2010},
  publisher={SIAM}
}

article{baydin2017automatic,
  title={Automatic differentiation in machine learning: a survey},
  author={Baydin, At{\i}l{\i}m G{\"u}nes and
          Pearlmutter, Barak A and
          Radul, Alexey Andreyevich and
          Siskind, Jeffrey Mark},
  journal={The Journal of Machine Learning Research},
  volume={18},
  number={1},
  pages={5595--5637},
  year={2017},
  publisher={JMLR. org}
}

@incollection{pytorch,
  title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
  author = {Paszke, Adam and
            Gross, Sam and
            Massa, Francisco and
            Lerer, Adam and
            Bradbury, James and
            Chanan, Gregory and
            Killeen, Trevor and
            Lin, Zeming and
            Gimelshein, Natalia and
            Antiga, Luca and
            Desmaison, Alban and
            Kopf, Andreas and
            Yang, Edward and
            DeVito, Zachary and
            Raison, Martin and
            Tejani, Alykhan and
            Chilamkurthy, Sasank and
            Steiner, Benoit and
            Fang, Lu and
            Bai, Junjie and
            Chintala, Soumith},
  booktitle = {Advances in Neural Information Processing Systems 32},
  editor = {H. Wallach and
            H. Larochelle and
            A. Beygelzimer and
            F. d\textquotesingle Alch\'{e}-Buc and
            E. Fox and
            R. Garnett},
  pages = {8024--8035},
  year = {2019},
  publisher = {Curran Associates, Inc.},
  url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@inproceedings{abadi2016tensorflow,
  title={Tensorflow: A system for large-scale machine learning},
  author={Abadi, Mart{\'\i}n and
          Barham, Paul and
          Chen, Jianmin and
          Chen, Zhifeng and
          Davis, Andy and
          Dean, Jeffrey and
          Devin, Matthieu and
          Ghemawat, Sanjay and
          Irving, Geoffrey and
          Isard, Michael and
          others},
  booktitle={12th $\{$USENIX$\}$ Symposium on Operating Systems Design and Implementation ($\{$OSDI$\}$ 16)},
  pages={265--283},
  year={2016}
}

software{jax2018github,
  author = {James Bradbury and
            Roy Frostig and
            Peter Hawkins and
            Matthew James Johnson and
            Chris Leary and
            Dougal Maclaurin and
            Skye Wanderman-Milne},
  title = {{JAX}: composable transformations of {P}ython+{N}um{P}y programs},
  url = {http://github.com/google/jax},
  version = {0.1.55},
  year = {2018},
}

book{engberg1986calculus,
  title={A calculus of communicating systems with label passing},
  author={Engberg, Uffe and
          Nielsen, Mogens},
  year={1986},
  url={https://doi.org/10.7146/dpb.v15i208.7559},
  doi={10.7146/dpb.v15i208.7559},
  publisher={Citeseer}
}

book{pym1991proof,
  title={Proof Search in the [lambda Pi]-calculus},
  author={Pym, David and
          Wallen, Lincoln A},
  year={1991},
  url={http://www.lfcs.inf.ed.ac.uk/reports/91/ECS-LFCS-91-146/ECS-LFCS-91-146.pdf},
  publisher={University of Edinburgh, Laboratory for Foundation of Computer Science}
}

article{milner1992functions,
  title={Functions as processes},
  author={Milner, Robin},
  journal={Mathematical structures in computer science},
  volume={2},
  number={2},
  pages={119--141},
  year={1992},
  url={https://doi.org/10.1017/S0960129500001407},
  doi={10.1017/S0960129500001407},
  publisher={Cambridge University Press}
}

article{boudol1998pi,
  title={The $\pi$-calculus in direct style},
  author={Boudol, G{\'e}rard},
  journal={Higher-Order and Symbolic Computation},
  volume={11},
  number={2},
  pages={177--208},
  year={1998},
  url={https://doi.org/10.1023/A:1010064516533},
  doi={10.1023/A:1010064516533},
  publisher={Springer}
}

@article{gentzen1935untersuchungen,
  title={Untersuchungen {\"u}ber das logische Schlie{\ss}en. I},
  author={Gentzen, Gerhard},
  journal={Mathematische zeitschrift},
  volume={39},
  number={1},
  pages={176--210},
  year={1935},
  url={https://doi.org/10.1007/BF01201353},
  doi={10.1007/BF01201353},
  publisher={Springer}
}

article{howard1980formulae,
  title={The formulae-as-types notion of construction},
  author={Howard, William A},
  journal={To HB Curry: essays on combinatory logic, lambda calculus and formalism},
  volume={44},
  pages={479--490},
  url={https://www.dcc.fc.up.pt/~acm/howard2.pdf},
  year={1980}
}

article{church1940formulation,
  title={A formulation of the simple theory of types},
  author={Church, Alonzo},
  journal={The journal of symbolic logic},
  volume={5},
  number={2},
  pages={56--68},
  year={1940},
  url={https://doi.org/10.2307/2266170},
  doi={10.2307/2266170},
  publisher={Cambridge University Press}
}

inproceedings{girard1971extension,
  title={Une extension de l'interpretation de Godel a l'analyse et son application a l'elimination des coupures dans l'analyse et la theorie des types},
  author={Girard, J-Y},
  booktitle={Proc. 2nd Scandinavian Logic Symp.},
  pages={63--92},
  year={1971},
  url={https://doi.org/10.1016/S0049-237X(08)70843-7},
  doi={10.1016/S0049-237X(08)70843-7},
  organization={North-Holland}
}

article{barras1997coq,
  title={The Coq proof assistant reference manual: Version 6.1},
  author={Barras, Bruno and
          Boutin, Samuel and
          Cornes, Cristina and
          Courant, Judica{\"e}l and
          Filliatre, Jean-Christophe and
          Gimenez, Eduardo and
          Herbelin, Hugo and
          Huet, Gerard and
          Munoz, Cesar and
          Murthy, Chetan and
          others},
  url={https://hal.inria.fr/inria-00069968/},
  year={1997}
}

@article{turing1936computable,
  title={On computable numbers, with an application to the Entscheidungsproblem},
  author={Turing, Alan Mathison},
  journal={J. of Math},
  volume={58},
  number={345-363},
  pages={5},
  url={https://www.wolframscience.com/prizes/tm23/images/Turing.pdf},
  year={1936}
}

book{martin1984intuitionistic,
  title={Intuitionistic type theory},
  author={Martin-L{\"o}f, Per and
          Sambin, Giovanni},
  volume={9},
  year={1984},
  url={http://people.csail.mit.edu/jgross/personal-website/papers/academic-papers-local/Martin-Lof80.pdf},
  publisher={Bibliopolis Naples}
}

phdthesis{coquand1986calculus,
  title={The calculus of constructions},
  author={Coquand, Thierry and
          Huet, G{\'e}rard},
  url={https://hal.inria.fr/inria-00076024},
  year={1986},
  school={INRIA}
}

inproceedings{huet1987induction,
  title={Induction principles formalized in the Calculus of Constructions},
  author={Huet, G{\'e}rard},
  booktitle={Colloquium on Trees in Algebra and Programming},
  pages={276--286},
  year={1987},
  url={https://doi.org/10.1007/3-540-17660-8_62},
  doi={10.1007/3-540-17660-8_62},
  organization={Springer}
}

article{barendregt_1991,
  title={Introduction to generalized type systems},
  volume={1},
  DOI={10.1017/S0956796800020025},
  url={https://doi.org/10.1017/S0956796800020025},
  number={2},
  journal={Journal of Functional Programming},
  publisher={Cambridge University Press},
  author={Barendregt, Henk},
  year={1991},
  pages={125–154}
}

article{berardi1988towards,
  title={Towards a mathematical analysis of the Coquand-Huet calculus of constructions and the other systems in Barendregt’s cube},
  author={Berardi, Stefano},
  journal={Technica1 report, Carnegie-Me11on University (USA) and Universita di Torino (Ita1y)},
  year={1988}
}

article{roorda2001pure,
  title={Pure type systems for functional programming},
  author={Roorda, J-W and
          Jeuring, JT},
  url={https://dspace.library.uu.nl/handle/1874/20854},
  year={2001}
}

article{guallart2015overview,
  title={An overview of type theories},
  author={Guallart, Nino},
  journal={Axiomathes},
  volume={25},
  number={1},
  pages={61--77},
  year={2015},
  url={https://doi.org/10.1007/s10516-014-9260-9},
  doi={10.1007/s10516-014-9260-9},
  publisher={Springer}
}

book{harper1986standard,
  title={Standard ml},
  author={Harper, Robert and
          MacQueen, David and
          Milner, Robin},
  year={1986},
  url={http://www.lfcs.inf.ed.ac.uk/reports/86/ECS-LFCS-86-2/ECS-LFCS-86-2.pdf},
  publisher={Department of Computer Science, University of Edinburgh}
}

article{syme2005f,
  title={The F\# 4.1 Language Specification},
  author={Syme, Don and
          Hu, Jack and
          Hoban, Luke and
          Liu, Tao and
          Lomov, Dmitry and
          Margetson, James and
          McNamara, Brian and
          Pamer, Joe and
          Orwick, Penny and
          Quirk, Daniel and
          others},
  url={https://fsharp.org/specs/language-spec/4.1/FSharpSpec-4.1-latest.pdf},
  year={2005}
}

article{leroy2014ocaml,
  title={The OCaml system release 4.02},
  author={Leroy, Xavier and
          Doligez, Damien and
          Frisch, Alain and
          Garrigue, Jacques and
          R{\'e}my, Didier and
          Vouillon, J{\'e}r{\^o}me},
  journal={Institut National de Recherche en Informatique et en Automatique},
  volume={54},
  url={https://sunsite.icm.edu.pl/packages/ocaml/ocaml-4.08/ocaml-4.08-refman.pdf},
  year={2014}
}

@book{jones2003haskell,
  title={Haskell 98 language and libraries: the revised report},
  author={Jones, Simon Peyton},
  year={2003},
  url={https://books.google.com/books?id=mMGQgcnCxjAC},
  publisher={Cambridge University Press}
}

inproceedings{norell2008dependently,
  title={Dependently typed programming in Agda},
  author={Norell, Ulf},
  booktitle={International school on advanced functional programming},
  pages={230--266},
  year={2008},
  url={https://doi.org/10.1007/978-3-642-04652-0_5},
  doi={978-3-642-04652-0_5},
  organization={Springer}
}

@article{selinger2008lecture,
  author    = {Peter Selinger},
  title     = {Lecture notes on the lambda calculus},
  journal   = {CoRR},
  volume    = {abs/0804.3434},
  year      = {2008},
  url       = {http://arxiv.org/abs/0804.3434},
  archivePrefix = {arXiv},
  eprint    = {0804.3434},
  timestamp = {Mon, 13 Aug 2018 16:48:04 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-0804-3434.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

book{draheim2017semantics,
  title={Semantics of the Probabilistic Typed Lambda Calculus: Markov Chain Semantics, Termination Behavior, and Denotational Semantics},
  author={Draheim, Dirk},
  year={2017},
  url={https://books.google.com/books?id=titBDgAAQBAJ},
  publisher={Springer}
}

@article{standard1996ebnf,
  title={Ebnf: Iso/iec 14977: 1996 (e)},
  author={Standard, EBNF Syntaxt Specification},
  url={http://www.cl.cam.ac.uk/mgk25/iso-14977.pdf},
  volume={70},
  year={1996}
}

article{baldi2014dropout,
  title={The dropout learning algorithm},
  author={Baldi, Pierre and
          Sadowski, Peter},
  journal={Artificial intelligence},
  volume={210},
  pages={78--122},
  year={2014},
  url={https://doi.org/10.1016/j.artint.2014.02.004},
  doi={10.1016/j.artint.2014.02.004},
  publisher={Elsevier}
}

%article{zhang2018three,
%  author    = {Guodong Zhang and
%               Chaoqi Wang and
%               Bowen Xu and
%               Roger B. Grosse},
%  title     = {Three Mechanisms of Weight Decay Regularization},
%  journal   = {CoRR},
%  volume    = {abs/1810.12281},
%  year      = {2018},
%  url       = {http://arxiv.org/abs/1810.12281},
%  archivePrefix = {arXiv},
%  eprint    = {1810.12281},
%  timestamp = {Thu, 01 Nov 2018 18:03:07 +0100},
%  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-12281.bib},
%  bibsource = {dblp computer science bibliography, https://dblp.org}
%}

@article{eisele2016log,
  title={The log-sum-exp trick in machine learning},
  author={Eisele, R},
  journal={Systems Architect and DBA},
  year={2016}
}

@article{chen1994weighted,
  title={Weighted finite population sampling to maximize entropy},
  author={Chen, Xiang-Hui and
          Dempster, Arthur P and
          Liu, Jun S},
  journal={Biometrika},
  volume={81},
  number={3},
  pages={457--469},
  year={1994},
  publisher={Oxford University Press}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and
          Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  url={https://arxiv.org/abs/1412.6980},
  year={2014}
}

@patent{mohamed2017neural,
  title={Neural network for program synthesis},
  author={Mohamed, Abdelrahman S.A. and
          Singh, Rishabh and
          Li, Lihong and
          Zhou, Dengyong and
          Kohli, Pushmeet and
          Parisotto, Emilio},
  url={https://patents.google.com/patent/US20180275967A1},
  year={2017},
  month={Mar},
  publisher={Google Patents},
  number={20180275967A1},
  nationality={United States}
}

@article{abadi2019simple,
  title={A simple differentiable programming language},
  author={Abadi, Mart{\'\i}n and
          Plotkin, Gordon D},
  journal={Proceedings of the ACM on Programming Languages},
  volume={4},
  number={POPL},
  pages={1--28},
  year={2019},
  publisher={ACM New York, NY, USA}
}

@misc{lachaux2020unsupervised,
    title={Unsupervised Translation of Programming Languages},
    author={Marie-Anne Lachaux and
            Baptiste Roziere and
            Lowik Chanussot and
            Guillaume Lample},
    year={2020},
    eprint={2006.03511},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@book{sun1994computational,
  title={Computational architectures integrating neural and symbolic processes: A perspective on the state of the art},
  author={Sun, Ron and
          Bookman, Lawrence A},
  volume={292},
  year={1994},
  publisher={Springer Science \& Business Media}
}

@article{deepblue,
  title={Deep blue},
  author={Campbell, Murray and
          Hoane Jr, A Joseph and
          Hsu, Feng-hsiung},
  journal={Artificial intelligence},
  volume={134},
  number={1-2},
  pages={57--83},
  year={2002},
  publisher={Elsevier}
}

@online{kasparov,
  author = {Kasparov, Garry},
  title = {Don't fear intelligent machines. Work with them},
  year = {2017},
  month = {Apr},
  type = {Talk},
  url = {https://www.ted.com/talks/garry_kasparov_don_t_fear_intelligent_machines_work_with_them},
  urldate = {2020-06-12}
}

@online{distillbo,
  author = {Agnihotri, Apoorv and
            Batra, Nipun},
  title = {Exploring Bayesian Optimization},
  year = {2020},
  month = {May},
  type = {Blog},
  url = {https://distill.pub/2020/bayesian-optimization/},
  urldate = {2020-06-13}
}

@article{gunning2017explainable,
  title={Explainable artificial intelligence (xai)},
  author={Gunning, David},
  journal={Defense Advanced Research Projects Agency (DARPA), nd Web},
  volume={2},
  year={2017}
}

@online{leakage,
  author = {Gutierrez, Daniel D.},
  title = {Ask a Data Scientist: Data Leakage},
  year = {2014},
  month = {Nov},
  type = {Blog},
  url = {https://insidebigdata.com/2014/11/26/ask-data-scientist-data-leakage/},
  urldate = {2020-06-27}
}

@article{kendall1944autoregressive,
  title={On autoregressive time series},
  author={Kendall, Maurice G},
  journal={Biometrika},
  pages={105--122},
  year={1944},
  publisher={JSTOR}
}
