\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx, color}
\usepackage[a4paper,margin=2cm]{geometry}
\usepackage{hyperref}
\usepackage[numbers]{natbib}
\usepackage{subfiles}
\usepackage{refcheck}

% \title{thesis proposal UvA MSc AI}
% \author{Tycho Grouwstra}
% \date{August 2019}

\begin{document}

\subfile{title-page-ai.tex}

\section{Research Direction}

If artificial intelligence is software 2.0~\citep{software20}
then \emph{program synthesis} is software 2.0 applied to the field of software development.

% synthesis
\emph{Program synthesis}~\citep{church1957applications} is the task to automatically construct a program%
~\footnote{While the definition of a program might be debatable as well, and there has been work on predicting type signatures from function names~\citep{wang2018predicting}, for the purpose of our paper we will focus on traditional executable programs, rather than 'programs' describing types.}%
that satisfies a given high-level specification,
be it a formal specification, a natural language description, or input-output examples.
% ~\footnote{\url{https://en.wikipedia.org/wiki/Program_synthesis}}

This differs from program induction, commonly known as 'supervised learning',
% TODO: SOURCE DEFINITIONS
in that fitting the model into the discrete form of a given grammar
forces one to instantiate such a model from probabilistic data interpretations,
whereas in traditional supervised learning,
such probabilistic interpretations of the data may be taken at prediction time.
% TODO: clarify relation to program induction
% TODO: clarify relation to supervised learning
% TODO: clarify relation to https://en.wikipedia.org/wiki/Constraint_programming incl SAT/SMT which seemed used a bunch
% TODO: clarify relation to https://en.wikipedia.org/wiki/Combinatorial_optimization

This means that in program synthesis, we are able to distill our modeled function
to a simplified discrete form that may well be intelligible to humans as well,
opening up opportunities for human-machine cooperation in writing software.
As such, program synthesis may bring \emph{hybrid intelligence} to the field of software development.

And in fact, in a novel functional programming paradigm called
\emph{type-driven development}~\footnote{\url{https://manning.com/books/type-driven-development-with-idris}}
based on typed holes, this is already happening.

% challenges
While considered a holy grail of computer science, program synthesis is a challenging task, characterized by large search spaces,
e.g. a space of $10^{5943}$ programs discovering an expert implementation of the MD5 hash function.~\cite{gulwani2017program}

% approaches
Program synthesis was traditionally studied as a computer science problem,
but has recently been explored using machine learning approaches under the name of neural program synthesis~\citep{nps}.
However, there has not yet been much work combining these two approaches.

% CS vs ML
Whereas the traditional approaches in program synthesis focused on constraining the large discrete search space,
neural program synthesis instead tends to incrementally generate programs,
using continuous representations of the state space to predict the next token,
be it in a sequential fashion~\citep{alphanpi},
or in a structured one based on abstract syntax trees (ASTs)~\citep{nsps}.

While the typically incremental approach of neural program synthesis breaks down the problem by considering one part of the program at a time, the original challenge remains.

Whereas a program synthesizer may be programmed or taught to output programs adhering to a given grammar,
there is typically no guarantee that such partial program constructions will qualify as a full executable program adherent to the grammar.
As a result, neural synthesizers will have little intermediary feedback to go by, limiting their effectiveness.

But if only complete programs can be evaluated for validity and behavior, then 
% for the duration of much of the incremental synthesis, the synthesizer has little feedback to go by.
it is much harder to provide synthesizers with an accurate understanding of incomplete programs.
% TODO: CONJECTURE, CITATION NEEDED?

Our key observation here is thus that input-output examples and types are quite complementary as specifications constraining our program behavior:
whereas input-output examples are relatively expressive, they may only help us to evaluate the quality of complete progress;
types, on the other hand, are by themselves not usually descriptive enough of our task,
but fortunately, due to typed holes,
may help us to evaluate and inform further synthesis even of incomplete functions still containing holes.

We therefore hypothesize that program synthesizers may thus capitalize on this synergy by utilizing both types of information,
rather than settling for only one of the two, as existing methods have done.%
~\footnote{While one might wonder if this constrains our idea to the subset of PBE problems where type information is available,
this limitation is essentially meaningless: when one has input-output examples, one should generally be able to infer their type.
This would render our idea applicable for practically any (neural) methods for PBE.}

Specifically, we hypothesize that the effectiveness of neural program synthesis may be improved by
% supervising incremental predictions offering additional features 
adding type information as additional features during training and testing.
% why types? differences from NLP, CS way, not reflected in ASTs in e.g. variables
% how to supervise with these? representation?

Furthermore, in an incremental node-based synthesis approach, we hypothesize that after each synthesis step,
languages featuring typed holes may help us to pre-compile even incomplete programs such as to provide immediate feedback.%
~\footnote{
    An alternative approach would be to enumerate any possible options for a given node,
    then filtering this list of options based on such compiler feedback.
    While this is indeed done for type-based program synthesis,
    % TODO: reference
    for neural program synthesis it poses the challenge of how to meaningfully combine these approaches.
    An additional concern is the scalability of enumerative approaches as the number of valid options grows.
}

% supervising using top-level type by inference through parametric return types (parametric polymorphism)? check parametrically typeable task ops e.g. from DILP?
% sequential monadic shit from DeepMind papers is useless...

% node-level types: probably matches how AI techniques are filtering already, but hard to confirm given lacking source code for NSPS

\emph{Research question: can neural program synthesis methods benefit from using types as additional features?}
% We hypothesize that the effectiveness of neural program synthesis may be improved by adding type information as additional features during training.
% TODO: add second question + research?
% TODO: try other program induction methods (used to reduce the search space) to apply for neural methods.
% TODO: how can we apply a more generalized program synthesis model to a specific problem? take inspiration from neural network pruning?
% TODO: investigate propagation of input-output examples to the smallest tree containing all holes, such as to map the encodings to the most precies space. this should mean inversely applying any pruned super-functions to the output examples. for lossless functions like map this should yield propagated output examples; for lossy functions such as filter this would instead yield type constraints (we know the elements that satisfied the condition, but around and between those there could be any number of elements that did not satisfy the constraint). I should check out to what extent such methods have been applied in type/example based program synthesis and theorem provers. caveat though, I dunno to what extent such type constraints could still be faster than fully calculating the input-output for various synthesized programs...

\section{Expected Contribution}\label{sec:expected-contribution}

The present work aims to be the first experiment to:
\begin{itemize}
    \item bring the type-based information traditionally used in program synthesis into the newer branch of neural program synthesis;
    \item bridge the two fields, such as to find a best-of-both-worlds golden mean;
    \item use this type info to better constrain the search space, improving the effectiveness of (neural) program synthesis methods. 
\end{itemize}

\section{Existing work}\label{sec:existing-work}

% TODO: give overview based on e.g. gulwani2017program / https://alexpolozov.com/blog/program-synthesis-2018/

% TODO: incorporate existing references

% TODO: add references
Methods used in program synthesis include evolutionary algorithms, reinforcement learning, bayesian optimization, sequence-to-sequence methods~\citep{neuralmachinetranslation}, active learning~\citep{shen2019using}, graph neural networks, satisfiability modulo theories (SMT) solvers~\citep{rosette,hornclauses,architecture}, and tree-based approaches such as recursive neural networks.

% TODO: expand on Myth paper somewhere

\subsection{Synthesis language}

% PBE
User intent in program synthesis can be expressed in various forms, including logical specification~\citep{temporalstreamlogic},
examples, traces, natural language~\citep{abstractsyntaxnetworks}, partial programs, or even related programs.~\citep{gulwani2017program}
%Program specifications in program synthesis may include formal program specifications, natural language descriptions of the program, as well as input-output examples, aka programming by example (PBE).
A synthesizer may be passed additional information in various ways:
\begin{itemize}
    \item further examples;
    \item more descriptive types~\citep{synquid};
    \item additional features describing properties of the function~\citep{odena2020learning}.
\end{itemize}

Such logical specifications might also include types of inputs and outputs,
and this branch of program synthesis has commonly focused on using functional programming languages as the synthesis language.%
~\citep{synquid,eguchi2018automated,scythe,scout,gissurarson2018suggesting,idris,lenses}
For our purposes here, we will focus on synthesis based on input-output examples, aka programming by example (PBE),
as having known input-output types will help provide us the needed type information we would like to use.

% structure
As we are interested in types, we will need to build upon AST-based (or node-based) rather than sequential (or token-based) synthesis methods.
% why?
1  % TODO check where this line came from.
Type-based approaches to synthesis are based on \emph{deductive search}, a top-down search strategy.
Such type-based deductive search is most powerful in a setting where the underlying DSL is loosely-constrained,
that is, permits arbitrary type-safe combinations of subexpressions.
In particular, any ML-like calculus with algebraic datatypes can serve as a core language for type-driven synthesis.~\citep{gulwani2017program}

% holes
Particularly useful for our purposes is a programming language feature called \emph{typed holes}~\citep{hashimoto1997typed},
as used in Agda~\footnote{\url{https://agda.readthedocs.io/en/latest/getting-started/quick-guide.html}},
Idris~\footnote{\url{http://docs.idris-lang.org/en/latest/tutorial/typesfuns.html\#holes}},
and Haskell~\footnote{\url{https://wiki.haskell.org/GHC/Typed_holes}}.
Typed holes allow one to write an incomplete functional program template,
enabling type inference for any such holes, in turn enabling suggested completions to the user.
Such interactive program synthesis has been labeled as the solver-aided
programming method \emph{sketching}~\citep{gulwani2017program} or
\emph{type-driven development}.
% ~\footnote{\url{https://manning.com/books/type-driven-development-with-idris}}
As such, one of our goals is to improve suggested hole completions in such languages to facilitate this interactive programming style.

% types
To get the most out of our types, we will want to provide them for:
\begin{itemize}
    \item inputs
    \item outputs
    \item abstract syntax trees (ASTs)
\end{itemize}

The basic idea here is simple: our program should return the desired type, while taking the desired input types.
% BNFs

However, in the simple case, the implications of this info do not require much computation:
one will just restrict their search to those AST nodes allowed for the present hole as dictated by the grammar.

% generics
What makes the use of types more powerful in restricting the search space is the use of \emph{parametric polymorphism}:
a function $append$ may work using either lists of numbers or lists of strings.
~\footnote{Left out of scope here are \emph{refinement types}, which further aid synthesis based on conditions.}
As such, its type signature may be made \emph{generic} such as to have its return type reflect the types of the parameters used.
Having such information available at the type level may add additional information over what is used in the simpler case above.

It should be noted however that not all programs benefit from this,
but only those for which potential building blocks include statically typed functions with parametric return types.

% decouple synthesis/target languages
As a result, this restriction limits our method from being used for direct synthesis of programming languages that are dynamically typed,
e.g. Ruby language, as well as to those lacking parametric polymorphism, e.g. C language.
However, this only partly hinders those wishing to synthesize programs in such languages:
rather than synthesizing in such languages directly, we would suggest synthesizing from the language that best constrains the search space,
then using source-to-source translation methods (e.g. neural machine translation~\citep{kalchbrenner2013recurrent})
using the synthesized program as input to obtain a program translated into the target language.
% TODO: make into experiment hypothesis?

% I'd lean toward a language with ML framework as the source language (Python/Haskell/OCaml?), and a target language with holes (Haskell/Idris/Agda) and proper type-checks (any but Python/Prolog). none of these used any of those; this intersection means a shared source/target language implies Haskell is the only option and I need to throw out existing implementations anyway. in terms of respectable benchmark, L^2 seems to actually have been used by others before.

% haskell
In other words, languages with stronger type systems are preferable for program synthesis.
This is well-known in the traditional program synthesis community,
where various researchers~\citep{synquid,hornclauses,scythe,gissurarson2018suggesting}
have been making use of the Haskell language,
a statically typed, purely functional programming language with type inference and lazy evaluation.~\footnote{\url{https://www.haskell.org/}}
% TODO: mention ML-like (= typed lisp) alternatives e.g. OCaml.

% TODO: move to related work
Note that other work in this area have used differentiable programming languages
as the synthesis language such as to enable optimization based on
stochastic gradient descent (SGD)~\citep{forth,terpret}.
However, such purely SGD-based methods proved less effective than traditional or mixed methods~\citep{terpret}.
More unfortunately for our purposes, such languages have generally been relatively imperative in nature,
rendering them less amenable to type-driven synthesis.
Outside of neural methods, programming languages designed for program synthesis also include solver-aided languages~\citep{rosette},
aimed at generating satisfiability conditions for satisfactory programs based on failing input-output examples such as to synthesize program repairs.

The advantages of Haskell as a synthesis language over the above-mentioned ML lies in its focus on the functional paradigm,
unlike e.g. OCaml: this paradigm is more amenable to static types, which for synthesis helps us constrain our search space.

Another advantage of Haskell over OCaml is it offers typed holes, which are useful for our purposes to evaluate the type of a given hole.
While Idris language offers these benefits as well, Haskell's lazy evaluation seems a more sensible default for our purposes than Idris's strict evaluation.
% TODO: justify why
~\footnote{As an interesting coincidence, using Haskell for program synthesis also means using an implementation of \citet{lambdacalculus}'s lambda calculus to address \citet{church1957applications}'s problem of synthesizing programs.}

% TODO: explain why I don't feel I need imperative statements or variable definitions
The reason we consider programs of a tree-based form, rather than as a list of imperative statements such as variable definitions,
is that the view of programs as function compositions guarantees us that any complete program will yield us output of the desired type.
This means we view our programs as \emp{pure functions}~\citep{fortran95},
i.e. returning a deterministic output for any given inputs, without performing any additional side effects.
This guarantees that, rather than just branching out, our search will focus on finding acceptable solutions.
This is to be contrasted with \emp{imperative} programs, a coding style characterized by variable mutation,
historically popularized for the purpose of performance optimization from the earlier languages such as assembly.
% TODO: explain incomplete programs, how types enable evaluation of these, and why this means we should perform program synthesis based on types

% TODO: explain why I don't feel I need imperative statements or variable definitions
The reason we consider programs of a tree-based form, rather than as a list of imperative statements such as variable definitions,
is that the view of programs as function compositions guarantees us that any complete program will yield us output of the desired type.
This means we view our programs as \emp{pure functions}~\citep{fortran95},
i.e. returning a deterministic output for any given inputs, without performing any additional side effects.
This guarantees that, rather than just branching out, our search will focus on finding acceptable solutions.
This is to be contrasted with \emp{imperative} programs, a coding style characterized by variable mutation,
historically popularized for the purpose of performance optimization from the earlier languages such as assembly.
Synthesis for such languages exists as well~\citep{shi2019frangel}, but is generally harder as it cannot make as much use of types.
% TODO: explain incomplete programs, how types enable evaluation of these, and why this means we should perform program synthesis based on types

Whereas modern programming languages might have a broad plethora of grammatical constructs available,
for the purpose of our proof-of-concept we will opt to hide much of this.
To achieve this, we will take inspiration from the lambda calculus~\citep{lambdacalculus},
which opts to view constructs as functions,
both so as to provide a unified view of various operations, as well as to enable \emph{currying} of functions.
A \emp{curried}~\citep{currying} version of a function is not unlike its original form,
yet allowing arguments to the function to be applied to it one at a time.
The way this works is that, when an argument is applied to a curried form of a function taking two parameters,
the result is a function that still takes one parameter, before yielding the actual result of the original function.
As such, viewing traditional operators such as addition as curried functions can both simplify the way we view things,
while also increasing expressiveness.
And in fact, this is indeed what happens in various functional languages,
where traditional operators such as \verb|+| are viewed simply as infix operator forms of curried functions.
In Haskell language, for example, \verb|+| may be used to refer to the addition operator in infix notation,
whereas \verb|(+)| may be used to refer to its form as a traditional function.
Other languages such as OCaml, Idris and Agda follow a similar pattern.

As such, we might express as curried functions not only basic mathematical operators,
but by wrapping them as library functions,
also traditional grammatical constructs as (functional) conditionals and function composition operators.
Whereas for legibility purposes, a programmer may prefer to read code using a grammar rich with syntactical sugar,
for the purpose of program synthesis,
it is preferable to decouple the syntax used for synthesis from that presented to the reader,
so as to prevent duplication during synthesis to restrict the search as much as possible.
Instead, a synthesized program might then be converted so as to use a more legible grammar.
For the purpose of this thesis, we will not focus on reader-friendly syntax, however.

Grammar-wise, this should leave us with few options:
referencing variables (whether from our library or parameters),
and applying arguments to functions.
For the sake of simplicity,
we will attempt to leave out certain common language features such as defining variables and creating lambda functions.
% ^ TODO: update statement on lambda functions
Hopefully, our idea can be demonstrated without this additional complexity.

To simplify the problem, we would disallow the use of any constant values such as free-style strings.
% TODO: evaluate the viability of this, and how to hack around availability of e.g. constant booleans.
% TODO: a proper solution here probably involves using e.g. https://hackage.haskell.org/package/ad to fix constants by backprop.

As a result, our Haskell-based grammar ends up looking as follows:
\begin{tabular}{ccccc}
    type & constructor & Type Parameters & example & note \\
    Exp & App & Exp Exp & exp exp & \\
    Exp & ExpTypeSig & Exp Type & exp \textbf{::} type & \\
    Exp & Paren & Exp & \textbf{(}exp\textbf{)} & \\
    Exp & Var & QName & qname & \\
    Type & TyApp & Type Type & Type Type & \\
    Type & TyCon & QName & QName & \\
    Type & TyFun & Type Type & Type \textbf{->} Type & \\
    Type & TyVar & Name & name & \\
    QName & UnQual & Name & name & redundant \\
    QName & Special & SpecialCon & specialCon & redundant \\
    Name & Ident & & ident & \\
    SpecialCon & ExprHole & & \textbf{_} & \\
    SpecialCon & ListCon & & \textbf{[]} & \\
    Exp & Lambda & [Pat] Exp & \textbf{\\} patt1 patt2 ... \textbf{->} exp & lambdas \\
    Pat & PVar & Name & name & lambdas, redundant \\
    Exp & Let & Binds Exp & \textbf{let} binds \textbf{in} exp & lambdas typed without ScopedTypeVariables \\
    Binds & BDecls & [Decl] & decl1\textbf{;} decl2\textbf{;} ... & lambdas typed without ScopedTypeVariables \\
    Decl & PatBind & Pat Rhs (Maybe Binds) & pat \textbf{=} rhs & lambdas typed without ScopedTypeVariables \\
    Rhs & UnGuardedRhs & Exp & exp & lambdas typed without ScopedTypeVariables, redundant \\
\end{tabular}
% TODO: use BNF?
% TODO: make this not specific to haskell by simplifying out the haskell-specific bits redundant here in my simple version

\section{Experiment}

\subsection{Benchmark task}

% TODO: benchmark algorithm
% - NSPS is closed due to IP issues -_-
% - NPI variants are sequence-based rather than AST-based
% - Batch Bayesian Optimization via Multi-objective Acquisition Ensemble for Automated Analog Circuit Design (http://proceedings.mlr.press/v80/lyu18a/lyu18a.pdf)
% - Programmatically Interpretable Reinforcement Learning (https://arxiv.org/pdf/1804.02477.pdf)
% - Towards Mixed Optimization for Reinforcement Learning with Program Synthesis (https://arxiv.org/pdf/1807.00403.pdf)
% - Program Synthesis using Conflict-Driven Learning (https://arxiv.org/pdf/1711.08029v1.pdf)

As a benchmark algorithm we will use~\cite{nsps}, a top-down incremental neural synthesis method which like other neural methods is not presently making use of type-level information.
% TODO: swap, no code available

% benchmark task:
% - [x] typed MIL: Prolog/Python, types: poly list, mono int/char.
% - [x] Myth: Haskell/OCaml, types: poly list/tree, mono bool/nat. third-party repo available but errors.
% - [x] lambda^2: OCaml/Python, types: poly list/tree, mono bool/num.
% - [x] NPI/AlphaNPI: task is sequential :(
% - [x] NSPS: flashfill so few parametric types :(, also tasks not publicized
% - DILP?: paper tests induction rather than synthesis, so adapting their benchmark makes it hard to compare -- just rules, no trees or types :(
% - [x] DeepCoder: dataset (/code) not published :(
% - [x] Suggesting Valid Hole Fits: based on types, not examples :(
% - [x] Synquid / Polymorphic Succinct Types: based on refinement types instead of i/o examples :(
% - [x] Scythe: no code :(, uses types + i/o examples. no (own) task! :(
% - [x] Scout: no code, and only extended abstract available, with no info on task :(
% - [x] Idris: based on types, not examples :(
% - [x] Houdini: tasks mostly involve neural networks so suck to evaluate :(
% - [x] Terpret: 12 tasks (table 2), also very binary so not very type-ey :(
% - [x] Tamandu: PBE with type-based pruning, but non-neural, so only evaluated on 23 functions
% https://docs.google.com/spreadsheets/d/1uDA9suwASDzllxJZDt--wZ0ci7q4eJIfPcAw9qr18-U/edit?usp=sharing

We had trouble finding suitable benchmark task in the literature.

On the one hand, especially benchmark tasks within non-neural program synthesis methods have usually consisted of only a limited number of tasks%
~\citep{myth,lambda2,typedmil,houdini,tamandu,dilp}~\cite{terpret},
as such non-neural methods do not require an equivalent to the training set typically used in machine learning setups.

% While \cite{lambda2} did not use neural methods,
On the other hand, benchmark tasks within Neural Program Synthesis have often remained somewhat simpler in nature,
rendering them less fit for our purposes --- either being imperative in nature (and as such being less amenable to types),
such as sorting tasks~\citep{npi,alphanpi},
or otherwise focusing on a simple set of types --- such as strings~\citep{nsps} ---%
or differently put, not including building blocks with parametric return types.

As a third issue, it was also common for existing papers to keep their datasets unpublished~\citep{nsps,deepcoder,tamandu}.

% As a benchmark task we will use \cite{lambda2}'s corpus of over 40 data structure manipulation tasks involving lists, trees, and nested data structures such as lists of lists or trees of lists.
% As their synthesis language \cite{lambda2} used the OCaml language~\footnote{\url{https://ocaml.org/}}, an industrial-strength programming language supporting functional, imperative and object-oriented styles.

As a result, it looks like we would need to create a benchmark task, or if anything a training dataset compatible with one of the existing benchmark tasks, ourselves.

Now, for compatibility we may simply ensure our test sets contain the benchmark tasks of existing papers.
To achieve this, we may increasingly add types, such as to support, in order of complexity:
\begin{itemize}
    \item list, bool~\citep{terpret}
    \item int~\citep{tamandu}
    \item char~\citep{typedmil}
    \item nat, tree~\citep{myth,lambda2}
\end{itemize}

We will do this by taking libraries of basic operations in accordance with these papers, then, in order to create a training set, generating any possible functions using combinations thereof within a given complexity threshold.

The hole filling is as follows:
\begin{itemize}
    % TODO: handle parameters ensuring their use
    \item we take our function, containing a number of parameters, a return type, and a body that contains holes;
    \item we enumerate the variables we have that could (if applicable, after function application) return a type compatible with our desired return type, to create versions of the function with said hole plugged with these variables (which in the case of functions, may, in turn, contain holes);
    % TODO: queue or whatever, any data structure really
    % TODO: distinguish unfilled currying slot vs unfilled holes
    \item we filter these potential programs given their number of remaining holes based on our complexity threshold;
    % TODO: specify complexity threshold
    \item we add the remaining programs to a queue of complete or incomplete programs, depending on whether they still contain holes;
    \item we similarly process the functions in the queue of incomplete programs, until we are left with an enumeration of complete programs;
    \item we evaluate the complete programs by the input-output examples, to filter down to those matching our behavioral criteria;
    \item finally, we generate sample inputs for each program, and calculate their corresponding outputs.
    % TODO: consider a depth-first alternative for lower memory complexity
    % TODO: compare to approach used in https://github.com/minori5214/programming-by-example/blob/master/generate.py
\end{itemize}

The process for generating task functions to traub our synthesizer on is as follows:
\begin{itemize}
    \item we start using a body consisting of a hole, typed with a wildcard;
    \item we use hole-filling to generate potential complete programs within a certain complexity threshold.
    % TODO: compare to approach used in https://github.com/minori5214/programming-by-example/blob/master/generate.py
\end{itemize}

The synthesis process itself is as follows:
\begin{itemize}
    \item we take the type of our function, along with a body consisting of a hole;
    \item we use hole-filling to generate potential complete programs;
    \item we generate sample inputs for each program, and calculate their corresponding outputs;
    \item we evaluate the complete programs by the input-output examples, to filter down to those matching our behavioral criteria;
    % TODO: consider a depth-first alternative for lower memory complexity
\end{itemize}

% TODO: EXPERIMENT
% TODO: elaborate how to supervise existing methods with type info

\section{Result}

Having added our type-level supervision during training, we expect synthesis success rates to rise and required evaluations to drop compared to the baseline algorithm.
This demonstrates that the findings from traditional program synthesis methods are relevant also in the field of neural program synthesis.

% TODO: RESULT

\section{Discussion}

One question we aim to answer here is whether our approach can meaningfully scale to program sizes not explicitly train on.
% TODO: check what claims NSPS made on this.

\nocite{*}
\bibliographystyle{acm}
\bibliography{references}

\end{document}
